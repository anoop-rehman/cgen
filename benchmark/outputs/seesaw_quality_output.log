
==========
== CUDA ==
==========

CUDA Version 12.4.1

Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.

This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license

A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience.

/usr/local/lib/python3.10/dist-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
No module named 'vllm._version'
  from vllm.version import __version__ as VLLM_VERSION
  [2m2025-09-10T18:25:50.298032Z[0m [33m WARN[0m  [33mStatus Code: 502. Retrying..., [1;33mrequest_id[0m[33m: ""[0m
    [2;3mat[0m /home/runner/work/xet-core/xet-core/cas_client/src/http_client.rs:220

  [2m2025-09-10T18:25:50.298063Z[0m [33m WARN[0m  [33mRetry attempt #0. Sleeping 304.137485ms before the next attempt[0m
    [2;3mat[0m /root/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/reqwest-retry-0.7.0/src/middleware.rs:171

Generating train split:   0%|          | 0/203037 [00:00<?, ? examples/s]Generating train split:   0%|          | 1000/203037 [00:00<00:32, 6177.79 examples/s]Generating train split:   1%|▏         | 3000/203037 [00:00<00:19, 10495.73 examples/s]Generating train split:   2%|▏         | 5000/203037 [00:00<00:15, 12514.37 examples/s]Generating train split:   3%|▎         | 7000/203037 [00:00<00:14, 13825.66 examples/s]Generating train split:   4%|▍         | 9000/203037 [00:00<00:13, 13923.34 examples/s]Generating train split:   5%|▌         | 11000/203037 [00:00<00:13, 14586.18 examples/s]Generating train split:   7%|▋         | 14536/203037 [00:01<00:13, 13807.81 examples/s]Generating train split:   8%|▊         | 16536/203037 [00:01<00:13, 13948.56 examples/s]Generating train split:   9%|▉         | 18536/203037 [00:01<00:13, 13844.77 examples/s]Generating train split:  10%|█         | 20536/203037 [00:01<00:12, 14166.36 examples/s]Generating train split:  11%|█         | 22536/203037 [00:01<00:13, 13768.89 examples/s]Generating train split:  12%|█▏        | 24536/203037 [00:01<00:12, 14149.58 examples/s]Generating train split:  14%|█▍        | 28072/203037 [00:02<00:12, 13539.51 examples/s]Generating train split:  15%|█▍        | 30072/203037 [00:02<00:12, 13705.03 examples/s]Generating train split:  16%|█▌        | 32072/203037 [00:02<00:12, 14012.40 examples/s]Generating train split:  17%|█▋        | 34072/203037 [00:02<00:11, 14198.73 examples/s]Generating train split:  18%|█▊        | 36072/203037 [00:02<00:11, 14279.42 examples/s]Generating train split:  19%|█▉        | 38072/203037 [00:02<00:11, 14659.42 examples/s]Generating train split:  20%|██        | 41608/203037 [00:03<00:12, 13371.98 examples/s]Generating train split:  21%|██▏       | 43608/203037 [00:03<00:12, 13257.71 examples/s]Generating train split:  22%|██▏       | 45608/203037 [00:03<00:11, 13408.31 examples/s]Generating train split:  23%|██▎       | 47608/203037 [00:03<00:11, 13838.27 examples/s]Generating train split:  24%|██▍       | 49608/203037 [00:03<00:11, 13883.86 examples/s]Generating train split:  25%|██▌       | 51608/203037 [00:03<00:10, 13903.71 examples/s]Generating train split:  27%|██▋       | 55144/203037 [00:04<00:11, 12916.00 examples/s]Generating train split:  28%|██▊       | 57144/203037 [00:04<00:11, 12981.04 examples/s]Generating train split:  29%|██▉       | 59144/203037 [00:04<00:10, 13266.80 examples/s]Generating train split:  30%|███       | 61144/203037 [00:04<00:10, 13225.83 examples/s]Generating train split:  31%|███       | 63144/203037 [00:04<00:10, 13309.27 examples/s]Generating train split:  32%|███▏      | 65144/203037 [00:04<00:10, 13594.32 examples/s]Generating train split:  33%|███▎      | 67680/203037 [00:04<00:08, 15608.77 examples/s]Generating train split:  34%|███▍      | 69680/203037 [00:05<00:10, 12358.41 examples/s]Generating train split:  35%|███▌      | 71680/203037 [00:05<00:10, 12245.69 examples/s]Generating train split:  36%|███▋      | 73680/203037 [00:05<00:10, 12427.33 examples/s]Generating train split:  37%|███▋      | 75680/203037 [00:05<00:09, 12805.60 examples/s]Generating train split:  38%|███▊      | 77680/203037 [00:05<00:09, 12871.29 examples/s]Generating train split:  39%|███▉      | 79680/203037 [00:05<00:09, 13108.87 examples/s]Generating train split:  40%|████      | 82216/203037 [00:06<00:09, 12575.97 examples/s]Generating train split:  41%|████▏     | 84216/203037 [00:06<00:09, 12718.69 examples/s]Generating train split:  42%|████▏     | 86216/203037 [00:06<00:09, 12873.13 examples/s]Generating train split:  43%|████▎     | 88216/203037 [00:06<00:08, 13007.24 examples/s]Generating train split:  44%|████▍     | 90216/203037 [00:06<00:09, 12501.72 examples/s]Generating train split:  45%|████▌     | 92216/203037 [00:06<00:08, 12726.04 examples/s]Generating train split:  47%|████▋     | 94752/203037 [00:07<00:07, 14649.47 examples/s]Generating train split:  48%|████▊     | 96752/203037 [00:07<00:08, 11966.39 examples/s]Generating train split:  49%|████▊     | 98752/203037 [00:07<00:08, 12063.45 examples/s]Generating train split:  50%|████▉     | 100752/203037 [00:07<00:08, 12470.68 examples/s]Generating train split:  51%|█████     | 102752/203037 [00:07<00:07, 12603.62 examples/s]Generating train split:  52%|█████▏    | 104752/203037 [00:07<00:07, 12403.91 examples/s]Generating train split:  53%|█████▎    | 106752/203037 [00:08<00:07, 12266.40 examples/s]Generating train split:  54%|█████▍    | 109288/203037 [00:08<00:07, 11992.69 examples/s]Generating train split:  55%|█████▍    | 111288/203037 [00:08<00:07, 11698.33 examples/s]Generating train split:  56%|█████▌    | 113288/203037 [00:08<00:07, 12458.30 examples/s]Generating train split:  57%|█████▋    | 115288/203037 [00:08<00:06, 12560.20 examples/s]Generating train split:  58%|█████▊    | 117288/203037 [00:08<00:06, 12821.45 examples/s]Generating train split:  59%|█████▉    | 119288/203037 [00:09<00:06, 12428.63 examples/s]Generating train split:  60%|█████▉    | 121288/203037 [00:09<00:06, 12714.11 examples/s]Generating train split:  60%|██████    | 122824/203037 [00:09<00:07, 11270.45 examples/s]Generating train split:  61%|██████▏   | 124824/203037 [00:09<00:06, 11647.32 examples/s]Generating train split:  62%|██████▏   | 126824/203037 [00:09<00:06, 11909.08 examples/s]Generating train split:  63%|██████▎   | 128824/203037 [00:09<00:06, 12186.73 examples/s]Generating train split:  64%|██████▍   | 130824/203037 [00:10<00:05, 12263.80 examples/s]Generating train split:  65%|██████▌   | 132824/203037 [00:10<00:05, 12725.95 examples/s]Generating train split:  67%|██████▋   | 135360/203037 [00:10<00:04, 15323.90 examples/s]Generating train split:  68%|██████▊   | 137360/203037 [00:10<00:05, 11782.31 examples/s]Generating train split:  69%|██████▊   | 139360/203037 [00:10<00:05, 12226.94 examples/s]Generating train split:  70%|██████▉   | 141360/203037 [00:10<00:04, 12414.62 examples/s]Generating train split:  71%|███████   | 143360/203037 [00:11<00:04, 12375.17 examples/s]Generating train split:  72%|███████▏  | 145360/203037 [00:11<00:04, 12855.68 examples/s]Generating train split:  73%|███████▎  | 147360/203037 [00:11<00:04, 13092.89 examples/s]Generating train split:  74%|███████▍  | 149896/203037 [00:11<00:04, 12215.70 examples/s]Generating train split:  75%|███████▍  | 151896/203037 [00:11<00:04, 12339.02 examples/s]Generating train split:  76%|███████▌  | 153896/203037 [00:11<00:04, 12087.37 examples/s]Generating train split:  77%|███████▋  | 155896/203037 [00:12<00:03, 12676.53 examples/s]Generating train split:  78%|███████▊  | 157896/203037 [00:12<00:03, 12649.27 examples/s]Generating train split:  79%|███████▉  | 159896/203037 [00:12<00:03, 13213.03 examples/s]Generating train split:  80%|████████  | 163432/203037 [00:12<00:03, 12717.69 examples/s]Generating train split:  81%|████████▏ | 165432/203037 [00:12<00:02, 12985.16 examples/s]Generating train split:  82%|████████▏ | 167432/203037 [00:12<00:02, 13222.20 examples/s]Generating train split:  83%|████████▎ | 169432/203037 [00:13<00:02, 13313.50 examples/s]Generating train split:  84%|████████▍ | 171432/203037 [00:13<00:02, 13590.16 examples/s]Generating train split:  85%|████████▌ | 173432/203037 [00:13<00:02, 13394.75 examples/s]Generating train split:  87%|████████▋ | 175967/203037 [00:13<00:01, 14761.65 examples/s]Generating train split:  88%|████████▊ | 177967/203037 [00:13<00:02, 12024.43 examples/s]Generating train split:  89%|████████▊ | 179967/203037 [00:13<00:01, 12475.94 examples/s]Generating train split:  90%|████████▉ | 181967/203037 [00:14<00:01, 11959.67 examples/s]Generating train split:  91%|█████████ | 183967/203037 [00:14<00:01, 11636.37 examples/s]Generating train split:  92%|█████████▏| 185967/203037 [00:14<00:01, 12715.74 examples/s]Generating train split:  93%|█████████▎| 187967/203037 [00:14<00:01, 13823.90 examples/s]Generating train split:  94%|█████████▍| 190502/203037 [00:14<00:01, 12524.33 examples/s]Generating train split:  95%|█████████▍| 192502/203037 [00:14<00:00, 12532.90 examples/s]Generating train split:  96%|█████████▌| 194502/203037 [00:15<00:00, 12660.95 examples/s]Generating train split:  97%|█████████▋| 196502/203037 [00:15<00:00, 12822.53 examples/s]Generating train split:  98%|█████████▊| 198502/203037 [00:15<00:00, 13080.90 examples/s]Generating train split:  99%|█████████▉| 200502/203037 [00:15<00:00, 12875.65 examples/s]Generating train split: 100%|█████████▉| 202502/203037 [00:15<00:00, 13396.44 examples/s]Generating train split: 100%|██████████| 203037/203037 [00:15<00:00, 12953.78 examples/s]
Generating validation split:   0%|          | 0/6436 [00:00<?, ? examples/s]Generating validation split:  16%|█▌        | 1000/6436 [00:00<00:00, 6591.59 examples/s]Generating validation split:  47%|████▋     | 3000/6436 [00:00<00:00, 11847.94 examples/s]Generating validation split:  78%|███████▊  | 5000/6436 [00:00<00:00, 12889.05 examples/s]Generating validation split: 100%|██████████| 6436/6436 [00:00<00:00, 13949.48 examples/s]
Generating test split:   0%|          | 0/6440 [00:00<?, ? examples/s]Generating test split:  16%|█▌        | 1000/6440 [00:00<00:00, 6450.75 examples/s]Generating test split:  47%|████▋     | 3000/6440 [00:00<00:00, 11656.80 examples/s]Generating test split:  78%|███████▊  | 5000/6440 [00:00<00:00, 13192.55 examples/s]Generating test split: 100%|██████████| 6440/6440 [00:00<00:00, 14274.20 examples/s]
2025-09-10 18:26:41.671 | INFO     | cgen.engine:__init__:335 - init process group using port 46953
/usr/local/lib/python3.10/dist-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
No module named 'vllm._version'
  from vllm.version import __version__ as VLLM_VERSION
/usr/local/lib/python3.10/dist-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
No module named 'vllm._version'
  from vllm.version import __version__ as VLLM_VERSION
/usr/local/lib/python3.10/dist-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
No module named 'vllm._version'
  from vllm.version import __version__ as VLLM_VERSION
/usr/local/lib/python3.10/dist-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
No module named 'vllm._version'
  from vllm.version import __version__ as VLLM_VERSION
2025-09-10 18:26:47.732 | INFO     | cgen.engine:__init__:97 - loading model...
2025-09-10 18:26:47.732 | INFO     | cgen.engine:__init__:98 - partitioning model...
2025-09-10 18:26:48.162 | INFO     | cgen.engine:__init__:97 - loading model...
2025-09-10 18:26:48.162 | INFO     | cgen.engine:__init__:98 - partitioning model...
2025-09-10 18:26:48.162 | INFO     | cgen.engine:__init__:97 - loading model...
2025-09-10 18:26:48.162 | INFO     | cgen.engine:__init__:98 - partitioning model...
2025-09-10 18:26:48.163 | INFO     | cgen.engine:__init__:97 - loading model...
2025-09-10 18:26:48.163 | INFO     | cgen.engine:__init__:98 - partitioning model...
2025-09-10 18:26:48.177 | INFO     | cgen.dist_utils:_create_process_groups:28 - create proc groups tp=0/1 pp=0/4
2025-09-10 18:26:48.177 | INFO     | cgen.dist_utils:_create_process_groups:28 - create proc groups tp=0/1 pp=3/4
2025-09-10 18:26:48.177 | INFO     | cgen.dist_utils:_create_process_groups:28 - create proc groups tp=0/1 pp=1/4
2025-09-10 18:26:48.177 | INFO     | cgen.dist_utils:_create_process_groups:28 - create proc groups tp=0/1 pp=2/4
2025-09-10 18:26:48.179 | INFO     | cgen.dist_utils:_create_process_groups:28 - create proc groups tp=0/4 pp=0/1
2025-09-10 18:26:48.179 | INFO     | cgen.dist_utils:_create_process_groups:28 - create proc groups tp=3/4 pp=0/1
2025-09-10 18:26:48.179 | INFO     | cgen.dist_utils:_create_process_groups:28 - create proc groups tp=1/4 pp=0/1
2025-09-10 18:26:48.179 | INFO     | cgen.dist_utils:_create_process_groups:28 - create proc groups tp=2/4 pp=0/1
INFO 09-10 18:26:48 utils.py:1008] Found nccl from library libnccl.so.2
INFO 09-10 18:26:48 utils.py:1008] Found nccl from library libnccl.so.2
INFO 09-10 18:26:48 pynccl.py:63] vLLM is using nccl==2.20.5
INFO 09-10 18:26:48 utils.py:1008] Found nccl from library libnccl.so.2
INFO 09-10 18:26:48 pynccl.py:63] vLLM is using nccl==2.20.5
INFO 09-10 18:26:48 utils.py:1008] Found nccl from library libnccl.so.2
INFO 09-10 18:26:48 pynccl.py:63] vLLM is using nccl==2.20.5
INFO 09-10 18:26:48 pynccl.py:63] vLLM is using nccl==2.20.5
  [2m2025-09-10T18:26:49.246856Z[0m [33m WARN[0m  [33mStatus Code: 502. Retrying..., [1;33mrequest_id[0m[33m: ""[0m
    [2;3mat[0m /home/runner/work/xet-core/xet-core/cas_client/src/http_client.rs:220

  [2m2025-09-10T18:26:49.246882Z[0m [33m WARN[0m  [33mRetry attempt #0. Sleeping 2.39474469s before the next attempt[0m
    [2;3mat[0m /root/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/reqwest-retry-0.7.0/src/middleware.rs:171

  [2m2025-09-10T18:26:59.879294Z[0m [33m WARN[0m  [33mStatus Code: 504. Retrying..., [1;33mrequest_id[0m[33m: ""[0m
    [2;3mat[0m /home/runner/work/xet-core/xet-core/cas_client/src/http_client.rs:220

  [2m2025-09-10T18:26:59.879320Z[0m [33m WARN[0m  [33mRetry attempt #0. Sleeping 1.057555188s before the next attempt[0m
    [2;3mat[0m /root/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/reqwest-retry-0.7.0/src/middleware.rs:171

  [2m2025-09-10T18:27:01.974638Z[0m [33m WARN[0m  [33mStatus Code: 504. Retrying..., [1;33mrequest_id[0m[33m: ""[0m
    [2;3mat[0m /home/runner/work/xet-core/xet-core/cas_client/src/http_client.rs:220

  [2m2025-09-10T18:27:01.974669Z[0m [33m WARN[0m  [33mRetry attempt #0. Sleeping 2.260434605s before the next attempt[0m
    [2;3mat[0m /root/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/reqwest-retry-0.7.0/src/middleware.rs:171

0it [00:00, ?it/s]0it [00:00, ?it/s]0it [00:00, ?it/s]0it [00:00, ?it/s]1it [00:00,  4.73it/s]1it [00:00,  5.03it/s]1it [00:00,  4.82it/s]84it [00:00, 245.74it/s]1it [00:00,  3.90it/s]23it [00:00, 80.29it/s]242it [00:00, 690.22it/s]4it [00:00, 10.69it/s]7it [00:00, 15.45it/s]13it [00:00, 22.76it/s]16it [00:00, 19.55it/s]36it [00:00, 35.40it/s]21it [00:01, 25.89it/s]123it [00:01, 256.01it/s]110it [00:01, 67.39it/s]44it [00:01, 32.31it/s]156it [00:01, 179.91it/s]50it [00:01, 32.56it/s]126it [00:01, 56.15it/s]55it [00:01, 25.84it/s]182it [00:01, 123.09it/s]61it [00:01, 30.38it/s]137it [00:02, 50.53it/s]66it [00:02, 24.93it/s]71it [00:02, 28.43it/s]145it [00:02, 41.49it/s]151it [00:02, 42.32it/s]75it [00:02, 22.33it/s]202it [00:02, 65.44it/s] 81it [00:02, 27.68it/s]223it [00:02, 271.89it/s]157it [00:03, 34.50it/s]163it [00:03, 34.41it/s]310it [00:03, 76.13it/s] 168it [00:03, 29.87it/s]217it [00:03, 45.79it/s]323it [00:03, 87.37it/s]
242it [00:03, 96.10it/s]323it [00:03, 84.29it/s]
0it [00:00, ?it/s]0it [00:00, ?it/s]242it [00:03, 51.53it/s]323it [00:03, 85.48it/s]
0it [00:00, ?it/s]266it [00:03, 108.51it/s]323it [00:03, 83.98it/s] 
0it [00:00, ?it/s]1it [00:00,  5.06it/s]1it [00:00,  4.94it/s]8it [00:00, 31.35it/s]1it [00:00,  4.36it/s]1it [00:00,  4.81it/s]7it [00:00, 26.48it/s]15it [00:00, 41.75it/s]7it [00:00, 23.75it/s]14it [00:00, 42.15it/s]7it [00:00, 25.72it/s]20it [00:00, 19.80it/s]13it [00:00, 15.93it/s]11it [00:00, 11.38it/s]16it [00:01, 15.80it/s]20it [00:01, 16.90it/s]24it [00:01, 19.38it/s]15it [00:01, 15.44it/s]21it [00:01, 21.66it/s]29it [00:01, 24.24it/s]25it [00:01, 20.53it/s]23it [00:01, 25.10it/s]25it [00:01, 24.09it/s]35it [00:01, 30.02it/s]34it [00:01, 31.12it/s]28it [00:01, 28.94it/s]33it [00:01, 35.09it/s]41it [00:01, 36.27it/s]39it [00:01, 33.33it/s]34it [00:01, 34.68it/s]46it [00:01, 38.27it/s]38it [00:01, 36.66it/s]45it [00:01, 37.54it/s]39it [00:01, 37.38it/s]53it [00:01, 44.76it/s]44it [00:01, 39.12it/s]51it [00:01, 41.60it/s]44it [00:01, 40.04it/s]59it [00:01, 45.07it/s]49it [00:01, 38.50it/s]57it [00:01, 41.23it/s]49it [00:01, 42.06it/s]65it [00:01, 47.69it/s]63it [00:01, 45.48it/s]55it [00:01, 39.51it/s]55it [00:01, 42.91it/s]73it [00:02, 54.71it/s]63it [00:02, 45.40it/s]69it [00:02, 43.08it/s]63it [00:01, 48.95it/s]79it [00:02, 47.85it/s]75it [00:02, 44.47it/s]68it [00:02, 43.24it/s]69it [00:02, 44.51it/s]85it [00:02, 45.61it/s]74it [00:02, 44.49it/s]83it [00:02, 49.11it/s]74it [00:02, 44.52it/s]91it [00:02, 47.77it/s]79it [00:02, 43.79it/s]89it [00:02, 46.49it/s]79it [00:02, 42.11it/s]96it [00:02, 44.54it/s]85it [00:02, 44.42it/s]95it [00:02, 47.87it/s]85it [00:02, 44.13it/s]103it [00:02, 47.21it/s]93it [00:02, 50.03it/s]103it [00:02, 52.08it/s]93it [00:02, 49.67it/s]108it [00:02, 47.10it/s]99it [00:02, 46.07it/s]99it [00:02, 47.89it/s]114it [00:02, 46.87it/s]109it [00:02, 45.03it/s]105it [00:02, 48.01it/s]107it [00:02, 53.06it/s]119it [00:03, 46.42it/s]115it [00:03, 46.83it/s]113it [00:03, 54.62it/s]113it [00:03, 52.83it/s]125it [00:03, 47.13it/s]121it [00:03, 47.44it/s]119it [00:03, 49.51it/s]119it [00:03, 51.49it/s]133it [00:03, 53.74it/s]127it [00:03, 47.93it/s]126it [00:03, 56.23it/s]127it [00:03, 53.33it/s]139it [00:03, 52.74it/s]134it [00:03, 49.43it/s]133it [00:03, 54.19it/s]133it [00:03, 54.80it/s]145it [00:03, 53.10it/s]140it [00:03, 50.02it/s]139it [00:03, 49.64it/s]154it [00:03, 56.90it/s]139it [00:03, 49.58it/s]146it [00:03, 48.73it/s]160it [00:03, 55.39it/s]145it [00:03, 48.59it/s]153it [00:03, 52.13it/s]145it [00:03, 48.12it/s]166it [00:03, 56.48it/s]153it [00:03, 55.28it/s]153it [00:03, 52.37it/s]159it [00:03, 48.18it/s]172it [00:03, 56.67it/s]159it [00:03, 50.74it/s]159it [00:03, 49.88it/s]167it [00:04, 52.67it/s]178it [00:04, 52.66it/s]165it [00:04, 50.46it/s]165it [00:04, 51.13it/s]174it [00:04, 53.64it/s]184it [00:04, 54.14it/s]174it [00:04, 56.96it/s]174it [00:04, 57.06it/s]181it [00:04, 56.62it/s]190it [00:04, 52.16it/s]180it [00:04, 56.43it/s]180it [00:04, 55.47it/s]196it [00:04, 50.85it/s]187it [00:04, 49.12it/s]186it [00:04, 57.15it/s]187it [00:04, 56.31it/s]203it [00:04, 51.59it/s]194it [00:04, 49.90it/s]193it [00:04, 56.70it/s]193it [00:04, 55.55it/s]201it [00:04, 53.86it/s]209it [00:04, 49.55it/s]199it [00:04, 51.06it/s]199it [00:04, 47.98it/s]207it [00:04, 51.17it/s]215it [00:04, 48.31it/s]205it [00:04, 47.93it/s]213it [00:04, 53.18it/s]205it [00:04, 47.12it/s]223it [00:04, 54.13it/s]214it [00:04, 53.44it/s]213it [00:04, 52.79it/s]219it [00:05, 49.27it/s]229it [00:05, 50.62it/s]220it [00:05, 53.27it/s]219it [00:05, 49.27it/s]225it [00:05, 47.24it/s]235it [00:05, 50.88it/s]227it [00:05, 54.44it/s]231it [00:05, 49.80it/s]225it [00:05, 48.61it/s]234it [00:05, 55.16it/s]237it [00:05, 52.12it/s]234it [00:05, 57.09it/s]242it [00:05, 32.72it/s]250it [00:05, 40.27it/s]243it [00:05, 32.91it/s]242it [00:05, 35.07it/s]258it [00:05, 47.04it/s]249it [00:05, 37.50it/s]242it [00:05, 33.67it/s]248it [00:05, 39.11it/s]265it [00:05, 51.47it/s]256it [00:05, 42.63it/s]248it [00:05, 36.96it/s]256it [00:05, 45.79it/s]272it [00:06, 55.04it/s]254it [00:05, 40.98it/s]262it [00:06, 48.32it/s]264it [00:06, 47.39it/s]279it [00:06, 51.46it/s]260it [00:06, 42.32it/s]268it [00:06, 48.24it/s]270it [00:06, 45.87it/s]285it [00:06, 51.19it/s]265it [00:06, 43.74it/s]274it [00:06, 49.50it/s]276it [00:06, 47.40it/s]292it [00:06, 55.39it/s]272it [00:06, 48.54it/s]280it [00:06, 47.27it/s]284it [00:06, 53.80it/s]298it [00:06, 52.15it/s]278it [00:06, 49.74it/s]286it [00:06, 47.50it/s]290it [00:06, 50.28it/s]304it [00:06, 53.18it/s]285it [00:06, 49.91it/s]294it [00:06, 52.05it/s]296it [00:06, 51.18it/s]310it [00:06, 48.71it/s]292it [00:06, 53.39it/s]304it [00:06, 55.96it/s]300it [00:06, 48.01it/s]298it [00:06, 50.77it/s]316it [00:06, 45.72it/s]310it [00:06, 52.71it/s]308it [00:06, 52.23it/s]304it [00:06, 52.32it/s]322it [00:07, 48.98it/s]323it [00:07, 45.62it/s]
316it [00:07, 51.63it/s]315it [00:07, 55.61it/s]310it [00:07, 52.98it/s]323it [00:07, 45.10it/s]
323it [00:07, 45.21it/s]
2025-09-10 18:27:27.191 | INFO     | cgen.engine:init_kvcache:236 - initializing kvcache
2025-09-10 18:27:27.191 | INFO     | cgen.engine:init_kvcache:236 - initializing kvcache
2025-09-10 18:27:27.198 | INFO     | cgen.engine:init_kvcache:256 - kvcache initialized, memory occupied: 4.38 GB
2025-09-10 18:27:27.198 | INFO     | cgen.engine:init_kvcache:256 - kvcache initialized, memory occupied: 4.14 GB
2025-09-10 18:27:27.207 | INFO     | cgen.engine:init_kvcache:236 - initializing kvcache
318it [00:07, 60.04it/s]2025-09-10 18:27:27.214 | INFO     | cgen.engine:init_kvcache:256 - kvcache initialized, memory occupied: 4.38 GB
323it [00:07, 45.15it/s]
2025-09-10 18:27:27.305 | INFO     | cgen.engine:init_kvcache:236 - initializing kvcache
2025-09-10 18:27:27.310 | INFO     | cgen.engine:init_kvcache:256 - kvcache initialized, memory occupied: 4.14 GB
2025-09-10 18:27:29.841 | INFO     | cgen.engine:init_shared_cache:262 - start allocating shared kvcache
2025-09-10 18:27:29.841 | INFO     | cgen.engine:init_shared_cache:262 - start allocating shared kvcache
2025-09-10 18:27:29.841 | INFO     | cgen.engine:init_shared_cache:262 - start allocating shared kvcache
2025-09-10 18:27:29.841 | INFO     | cgen.engine:init_shared_cache:262 - start allocating shared kvcache
2025-09-10 18:27:30.165 | INFO     | cgen.engine:init_shared_cache:278 - launch prefetcher
2025-09-10 18:27:30.165 | INFO     | cgen.engine:init_shared_cache:278 - launch prefetcher
2025-09-10 18:27:30.165 | INFO     | cgen.engine:init_shared_cache:278 - launch prefetcher
2025-09-10 18:27:30.165 | INFO     | cgen.engine:init_shared_cache:278 - launch prefetcher
2025-09-10 18:27:30.165 | INFO     | cgen.engine:init_shared_cache:279 - 3 <torch.cuda.Stream device=cuda:3 cuda_stream=0x0> 
2025-09-10 18:27:30.165 | INFO     | cgen.engine:init_shared_cache:279 - 0 <torch.cuda.Stream device=cuda:0 cuda_stream=0x0> 
2025-09-10 18:27:30.165 | INFO     | cgen.engine:init_shared_cache:279 - 1 <torch.cuda.Stream device=cuda:1 cuda_stream=0x0> 
2025-09-10 18:27:30.165 | INFO     | cgen.engine:init_shared_cache:279 - 2 <torch.cuda.Stream device=cuda:2 cuda_stream=0x0> 
self.watermark_blocks=50.0
Processed prompts:   0%|          | 0/10 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts:   0%|          | 0/10 [00:01<?, ?it/s, est. speed input: 8000.94 toks/s, output: 0.00 toks/s]Processed prompts:   0%|          | 0/10 [00:02<?, ?it/s, est. speed input: 6827.21 toks/s, output: 0.00 toks/s]Processed prompts:   0%|          | 0/10 [00:02<?, ?it/s, est. speed input: 7390.93 toks/s, output: 0.00 toks/s]2025-09-10 18:27:32.723 | INFO     | cgen.schedule:to_decode:83 - switch to decode, seqs in CPU 1, prefetching 3, seqs in GPU 0
2025-09-10 18:27:32.723 | INFO     | cgen.schedule:update_prefetch:252 - waiting for prefetching...
2025-09-10 18:27:32.824 | INFO     | cgen.schedule:update_prefetch:252 - waiting for prefetching...
2025-09-10 18:27:32.924 | INFO     | cgen.schedule:update_prefetch:252 - waiting for prefetching...
2025-09-10 18:27:33.025 | INFO     | cgen.schedule:update_prefetch:252 - waiting for prefetching...
2025-09-10 18:27:33.125 | INFO     | cgen.schedule:update_prefetch:252 - waiting for prefetching...
2025-09-10 18:27:33.876 | INFO     | cgen.engine:to_decode:175 - convert from prefill to decode time:  0.34 s
Processed prompts:   0%|          | 0/10 [00:03<?, ?it/s, est. speed input: 4807.72 toks/s, output: 0.26 toks/s]Processed prompts:   0%|          | 0/10 [00:03<?, ?it/s, est. speed input: 4680.68 toks/s, output: 3.30 toks/s]Processed prompts:   0%|          | 0/10 [00:04<?, ?it/s, est. speed input: 4563.43 toks/s, output: 6.18 toks/s]Processed prompts:   0%|          | 0/10 [00:04<?, ?it/s, est. speed input: 4452.27 toks/s, output: 8.93 toks/s]Processed prompts:   0%|          | 0/10 [00:04<?, ?it/s, est. speed input: 4344.50 toks/s, output: 11.54 toks/s]Processed prompts:   0%|          | 0/10 [00:04<?, ?it/s, est. speed input: 4242.60 toks/s, output: 14.03 toks/s]Processed prompts:   0%|          | 0/10 [00:04<?, ?it/s, est. speed input: 4146.02 toks/s, output: 16.40 toks/s]Processed prompts:   0%|          | 0/10 [00:04<?, ?it/s, est. speed input: 4054.03 toks/s, output: 18.68 toks/s]Processed prompts:   0%|          | 0/10 [00:04<?, ?it/s, est. speed input: 3965.10 toks/s, output: 20.85 toks/s]Processed prompts:   0%|          | 0/10 [00:04<?, ?it/s, est. speed input: 3880.12 toks/s, output: 22.92 toks/s]Processed prompts:   0%|          | 0/10 [00:04<?, ?it/s, est. speed input: 3798.59 toks/s, output: 24.91 toks/s]Processed prompts:   0%|          | 0/10 [00:04<?, ?it/s, est. speed input: 3720.40 toks/s, output: 26.82 toks/s]Processed prompts:   0%|          | 0/10 [00:05<?, ?it/s, est. speed input: 3635.59 toks/s, output: 28.57 toks/s]Processed prompts:   0%|          | 0/10 [00:05<?, ?it/s, est. speed input: 3564.19 toks/s, output: 30.33 toks/s]Processed prompts:   0%|          | 0/10 [00:05<?, ?it/s, est. speed input: 3495.71 toks/s, output: 32.02 toks/s]Processed prompts:   0%|          | 0/10 [00:05<?, ?it/s, est. speed input: 3427.57 toks/s, output: 33.63 toks/s]Processed prompts:   0%|          | 0/10 [00:05<?, ?it/s, est. speed input: 3356.78 toks/s, output: 35.11 toks/s]Processed prompts:   0%|          | 0/10 [00:05<?, ?it/s, est. speed input: 3295.20 toks/s, output: 36.61 toks/s]Processed prompts:   0%|          | 0/10 [00:05<?, ?it/s, est. speed input: 3235.21 toks/s, output: 38.05 toks/s]Processed prompts:   0%|          | 0/10 [00:05<?, ?it/s, est. speed input: 3177.59 toks/s, output: 39.44 toks/s]Processed prompts:   0%|          | 0/10 [00:05<?, ?it/s, est. speed input: 3122.02 toks/s, output: 40.78 toks/s]Processed prompts:   0%|          | 0/10 [00:06<?, ?it/s, est. speed input: 3068.86 toks/s, output: 42.08 toks/s]Processed prompts:   0%|          | 0/10 [00:06<?, ?it/s, est. speed input: 3017.53 toks/s, output: 43.34 toks/s]Processed prompts:   0%|          | 0/10 [00:06<?, ?it/s, est. speed input: 2967.85 toks/s, output: 44.56 toks/s]Processed prompts:   0%|          | 0/10 [00:06<?, ?it/s, est. speed input: 2919.87 toks/s, output: 45.74 toks/s]Processed prompts:   0%|          | 0/10 [00:06<?, ?it/s, est. speed input: 2873.18 toks/s, output: 46.87 toks/s]Processed prompts:   0%|          | 0/10 [00:06<?, ?it/s, est. speed input: 2827.62 toks/s, output: 47.97 toks/s]Processed prompts:   0%|          | 0/10 [00:06<?, ?it/s, est. speed input: 2783.86 toks/s, output: 49.04 toks/s]Processed prompts:   0%|          | 0/10 [00:06<?, ?it/s, est. speed input: 2741.58 toks/s, output: 50.08 toks/s]Processed prompts:   0%|          | 0/10 [00:06<?, ?it/s, est. speed input: 2700.60 toks/s, output: 51.08 toks/s]Processed prompts:   0%|          | 0/10 [00:06<?, ?it/s, est. speed input: 2660.77 toks/s, output: 52.06 toks/s]Processed prompts:   0%|          | 0/10 [00:07<?, ?it/s, est. speed input: 2622.05 toks/s, output: 53.01 toks/s]Processed prompts:   0%|          | 0/10 [00:07<?, ?it/s, est. speed input: 2584.39 toks/s, output: 53.93 toks/s]Processed prompts:   0%|          | 0/10 [00:07<?, ?it/s, est. speed input: 2547.84 toks/s, output: 54.82 toks/s]Processed prompts:   0%|          | 0/10 [00:07<?, ?it/s, est. speed input: 2512.00 toks/s, output: 55.69 toks/s]Processed prompts:   0%|          | 0/10 [00:07<?, ?it/s, est. speed input: 2477.38 toks/s, output: 56.53 toks/s]Processed prompts:   0%|          | 0/10 [00:07<?, ?it/s, est. speed input: 2443.74 toks/s, output: 57.35 toks/s]Processed prompts:  10%|█         | 1/10 [00:07<01:08,  7.65s/it, est. speed input: 2411.14 toks/s, output: 58.02 toks/s]Processed prompts:  20%|██        | 2/10 [00:08<00:33,  4.13s/it, est. speed input: 2236.34 toks/s, output: 59.64 toks/s]Processed prompts:  30%|███       | 3/10 [00:12<00:28,  4.02s/it, est. speed input: 1529.40 toks/s, output: 77.42 toks/s]Processed prompts:  40%|████      | 4/10 [00:12<00:18,  3.05s/it, est. speed input: 1513.55 toks/s, output: 76.95 toks/s]2025-09-10 18:27:42.457 | INFO     | cgen.schedule:to_prefill:78 - switch to prefill, seqs in CPU 1, prefetching 0, seqs in GPU 3
2025-09-10 18:27:42.763 | INFO     | cgen.schedule:to_decode:83 - switch to decode, seqs in CPU 1, prefetching 0, seqs in GPU 3
2025-09-10 18:27:42.764 | INFO     | cgen.engine:to_prefill:162 - convert from decode to prefill time:  0.31 s
2025-09-10 18:27:44.318 | INFO     | cgen.engine:to_decode:175 - convert from prefill to decode time:  0.61 s
Processed prompts:  50%|█████     | 5/10 [00:15<00:15,  3.01s/it, est. speed input: 1549.09 toks/s, output: 69.89 toks/s]Processed prompts:  60%|██████    | 6/10 [00:16<00:10,  2.73s/it, est. speed input: 1422.96 toks/s, output: 73.61 toks/s]Processed prompts:  70%|███████   | 7/10 [00:18<00:08,  2.68s/it, est. speed input: 1242.72 toks/s, output: 78.37 toks/s]Processed prompts:  80%|████████  | 8/10 [00:19<00:04,  2.47s/it, est. speed input: 1180.87 toks/s, output: 78.52 toks/s]Processed prompts:  90%|█████████ | 9/10 [00:24<00:02,  2.76s/it, est. speed input: 937.83 toks/s, output: 78.75 toks/s] Processed prompts: 100%|██████████| 10/10 [00:40<00:00,  4.08s/it, est. speed input: 571.42 toks/s, output: 65.81 toks/s]Processed prompts: 100%|██████████| 10/10 [00:40<00:00,  4.08s/it, est. speed input: 571.42 toks/s, output: 65.81 toks/s]
detokenizer takes 0.01 s
=== Sample Model Outputs (First 20) ===

Sample 1:
Input: the segmentation process as a whole can be thought of as consisting of two tasks : recognition and delineation . 
 recognition is to determine roughly `` where '' the object is and to distinguish it from other object - like entities . 
 although delineation is the final step for defining the spatial extent of the object region / boundary in the image , an efficient recognition strategy is a key for successful delineation . in this study , 
 a novel , general method is introduced for object recognition to assist in segmentation ( delineation ) tasks . 
 it exploits the pose relationship that can be encoded , via the concept of ball scale ( b - scale )  @xcite , between the binary training objects and their associated images .    as an alternative to the manual methods based on initial placement of the models by an expert  @xcite in the literature , 
 model based methods can be employed for recognition . 
 for example , in @xcite , the position of an organ model ( such as liver ) is estimated by its histogram . in  @xcite , 
 generalized hough transform is succesfully extended to incorporate variability of shape for 2d segmentation problem . 
 atlas based methods are also used to define initial position for a shape model . in  @xcite 
 , affine registration is performed to align the data into an atlas to determine the initial position for a shape model of the knee cartilage . 
 similarly , a popular particle filtering algorithm is used to detect the starting pose of models for both single and multi - object cases  @xcite . however , due to the large search space and numerous local minimas in most of these studies , conducting a global search on the entire image is not a feasible approach . in this paper 
 , we investigate an approach of automatically recognizing objects in 3d images without performing elaborate searches or optimization . 
 the proposed method consists of the following key ideas and components :    * 1 . 
 model building : * after aligning image data from all @xmath0 subjects in the training set into a common coordinate system via 7-parameter affine registration , the live - wire algorithm  @xcite is used to segment @xmath1 different objects from @xmath0 subjects . 
 segmented objects are used for the automatic extraction of landmarks in a slice - by - slice manner  @xcite . from the landmark information for all objects , 
 a model assembly @xmath2 is constructed . 
 b - scale encoding : * the b - scale value at every voxel in an image helps to understand `` objectness '' of a given image without doing explicit segmentation . for each voxel , 
 the radius of the largest ball of homogeneous intensity is weighted by the intensity value of that particular voxel in order to incorporate appearance ( texture ) information into the object information ( called intensity weighted b - scale : @xmath3 ) so that a model of the correlations between shape and texture can be built . a simple and proper way of thresholding the b - scale image yields a few largest balls remaining in the image . 
 these are used for the construction of the relationship between the segmented training objects and the corresponding images . 
 the resulting images have a strong relationship with the actual delineated objects . 
 relationship between @xmath2 and @xmath3 : * a principal component @xmath4 system is built via pca for the segmented objects in each image , and their mean @xmath5 system , denoted @xmath6 , is found over all training images . 
 @xmath6 has an origin and three @xmath5 axes . 
 similarly the mean @xmath5 system , denoted @xmath7 , for intensity weighted b - scale images @xmath8 is found . 
 finally the transformation @xmath9 that maps @xmath7 to @xmath6 is found . 
 given an image @xmath10 to be segmented , the main idea here is to use @xmath9 to facilitate a quick placement of @xmath2 in @xmath10 with a proper pose as indicated in step 4 below .    * 
 hierarchical recognition : * for a given image @xmath10 , @xmath3 is obtained and its @xmath5 system , denoted @xmath11 is computed subsequently . assuming the relationship of @xmath11 to @xmath6 to be the same as of @xmath7 to @xmath6 , and assuming that @xmath6 offers the proper pose of @xmath2 in the training images , we use transformation @xmath9 and @xmath11 to determine the pose of @xmath2 in @xmath10 . 
 this level of recognition is called coarse recognition . further refinement of the recognition can be done using the skin boundary object in the image with the requirement that a major portion of @xmath2 should lie inside the body region delimited by the skin boundary . moreover 
 , a little search inside the skin boundary can be done for the fine tuning , however , since offered coarse recognition method gives high recognition rates , there is no need to do any elaborate searches . 
 we will focus on the fine tuning of coarse recognition for future study . 
 the finest level of recognition requires the actual delineation algorithm itself , which is a hybrid method in our case and called gc - asm ( synergistic integration of graph - cut and active shape model ) . 
 this delineation algorithm is presented in a companion paper submitted to this symposium  @xcite . 
 a convenient way of achieving incorporation of prior information automatically in computing systems is to create and use a flexible _ model _ to encode information such as the expected _ size _ , _ shape _ , _ appearance _ , and _ position _ of objects in an image  @xcite . among such information , 
 _ shape _ and _ appearance _ are two complementary but closely related attributes of biological structures in images , and hence they are often used to create statistical models . in particular , shape has been used both in high and low level image analysis tasks extensively , and it has been demonstrated that shape models ( such as active shape models ( asms ) ) can be quite powerful in compensating for misleading information due to noise , poor resolution , clutter , and occlusion in the images  @xcite . 
 therefore , we use asm  @xcite to estimate population statistics from a set of examples ( training set ) . in order to guarantee 3d point correspondences required by asm 
 , we build our statistical shape models combining semi - automatic methods : ( 1 ) manually selected anatomically correspondent slices by an expert , and ( 2 ) semi - automatic way of specifying key points on the shapes starting from the same anatomical locations . 
 once step ( 1 ) is accomplished , the remaining problem turns into a problem of establishing point correspondence in 2d shapes , which is easily solved . 
 it is extremely significant to choose correct correspondences so that a good representation of the modelled object results . 
 although landmark correspondence is usually established manually by experts , it is time - consuming , prone to errors , and restricted to only 2d objects  @xcite . 
 because of these limitations , a semi - automatic landmark tagging method , _ equal space landmarking _ , is used to establish correspondence between landmarks of each sample shape in our experiments . 
 although this method is proposed for 2d objects , and equally spacing a fixed number of points for 3d objects is much more difficult , we use equal space landmarking technique in pseudo-3d manner where 3d object is annotated slice by slice . 
 let @xmath12 be a single shape and assume that its finite dimensional representation after the landmarking consisting of @xmath13 landmark points with positions @xmath14 , where @xmath15 are cartesian coordinates of the @xmath16 point on the shape @xmath17 . 
 equal space landmark tagging for points @xmath18 for @xmath19 on shape boundaries ( contours ) starts by selecting an initial point on each shape sample in training set and equally space a fixed number of points on each boundary automatically  @xcite . selecting the starting point 
 has been done manually by annotating the same anatomical point for each shape in the training set . 
 figure  [ img : landmarking_abd ] shows annotated landmarks for five different objects ( skin , liver , right kidney , left kidney , spleen ) in a ct slice of the abdominal region . 
 note that different number of landmarks are used for different objects considering their size .    [ cols="^ " , ] 
 \(1 ) the b - scale image of a given image captures object morphometric information without requiring explicit segmentation . 
 b - scales constitute fundamental units of an image in terms of largest homogeneous balls situated at every voxel in the image . 
 the b - scale concept has been previously used in object delineation , filtering and registration . 
 our results suggest that their ability to capture object geography in conjunction with shape models may be useful in quick and simple yet accurate object recognition strategies . 
 ( 2 ) the presented method is general and does not depend on exploiting the peculiar characteristics of the application situation . 
 ( 3 ) the specificity of recognition increases dramatically as the number of objects in the model increases . 
 ( 4 ) we emphasize that both modeling and testing procedures are carried out on the ct data sets that are part of the clinical pet / ct data routinely acquired in our hospital . 
 the ct data set are thus of relatively poor ( spatial and contrast ) resolution compared to other ct - alone studies with or without contrast . 
 we expect better performance if higher resolution ct data are employed in modeling or testing . 
 this paper is published in spie medical imaging conference - 2010 . 
 falcao , a.x . , 
 udupa , j.k . , 
 samarasekera , s. , sharma , s. , hirsch , b.e . , and lotufo , r.a . , 1998 
 user - steered image segmentation paradigms : live wire and live lane . graph . 
 models image process . 
 60  ( 4 ) , pp . 
 233260 . 
 kokkinos , i. , maragos , p. , 2009 . 
 synergy between object recognition and image segmentation using the expectation - maximization algorithm . 
 ieee transactions on pattern analysis and machine intelligience , vol.31  ( 8) , pp.14861501 . 
 brejl , m. , sonka , m. , 2000 . 
 object localization and border detection criteria design in edge - based image segmentation : automated learning from examples . 
 ieee transactions on medical imaging , vol.19  ( 10 ) , pp.973985 . 
 fripp , j. , crozier , s. , warfield , s.k . , 
 ourselin , s. , 2005 . 
 automatic initialisation of 3d deformable models for cartilage segmentation . in proceedings of digital image computing : techniques and applications , pp .
Generated: 
 10111016 . 
 2005 . 
 2005 . 
 2005 . 
 2005 . 
 2005 . 
 2005 . 
 2005 . 
 2005 . 
 2005 . 
 2005 . 
 2005 . 
 2005 . 
 2005 . 
 2005 . 
 2005 . 
 2005 . 
 2005 . 
 2005 . 
 2005 . 
 2005 . 
 2005 . 
 2005 . 
 2005 . 
 2005 . 
 2005 . 
 2005 . 
 2005 . 
 2005 . 
 2005 . 
 2005 . 
 2005 . 
 2005 . 
 2005 . 
 2005 . 
 2005 . 
 2005 . 
 2005 . 
 2005 . 
 2005 . 
 2005 . 
 2005 . 
 2005 . 
 2005 . 
 2005
--------------------------------------------------------------------------------

Sample 2:
Input: studies of charm decays are pursued for several different reasons . 
 first of all , there is the possibility of directly observing new physics beyond the standard model ( sm ) , since the effects of cp violation due to sm processes is highly suppressed allowing new physics contributions to be more easily seen than in @xmath8 decays where the sm processes typically have large effects @xcite . @xmath1 
 mixing also is interesting because it could come from either sm or new physics ( np ) processes , and could teach us interesting lessons . 
 another important reason for detailed charm studies is that most @xmath8 s , @xmath999% , decay into charm , so knowledge about charm decays is particularly useful for @xmath8 decay studies . 
 especially interesting are absolute branching ratios , resonant substructures in multi - body decays , phases on dalitz plots , etc .. other heavier objects such as top quarks decay into @xmath8 quarks and higgs particles may decay with large rates to @xmath10 , again making charm studies important . 
 furthermore , charm can teach us a great deal about strong interactions , especially decay constants and final state interactions . 
 charm has been studied at @xmath11 colliders at threshold , first by the mark iii collaboration and more recently by bes and cleo - c , at higher @xmath11 energies , and at fixed target and hadron collider experiments @xcite . 
 the detection techniques are rather different at threshold than in other experiments . 
 the @xmath12 resonance decays into @xmath13 ; the world average cross - section is 3.72@xmath140.09 nb for @xmath15 production and 2.82@xmath140.09 nb for @xmath16 production @xcite . 
 @xmath5 production is studied at 4170 mev , where the cross - section for @xmath17+@xmath18 is @xmath91 nb @xcite . the underlying light quark 
 continuum " background is about 14 nb . 
 the relatively large cross - sections , relatively large branching ratios and sufficient luminosities , allow experiments to fully reconstruct one @xmath19 as a  tag . " 
 since the charge and flavor of the tag is then uniquely determined , the rest of the event can be examined for characteristics of the other  known " particle . to measure absolute branching ratios , for example at the @xmath12 , the rest of the event is fully reconstructed , as well as the tag .    at the @xmath12 @xmath19 meson final states are reconstructed by first evaluating the difference in the energy , @xmath20 , of the decay products with the beam energy . candidates with @xmath20 consistent with zero are selected and then the @xmath19 beam - constrained mass is evaluated , @xmath21 where @xmath22 runs over all the final state particles . 
 examples of single and double reconstruction are presented in fig . 
 [ cleo - double](a ) that shows the @xmath23 distribution for a @xmath24 or @xmath25 final states . 
 these  single tags " show a large signal and a very small background . 
 [ cleo - double](b ) shows a  double " tag sample where both @xmath3 and @xmath26 candidates in the same event are reconstructed . 
 distributions for candidates from either @xmath24 or @xmath25 modes . 
 ( b ) the @xmath27 distribution for candidates for candidates from @xmath24 and @xmath25 modes . 
 the solid curves are a fits to the signals plus the backgrounds , that are indicated by the dashed shapes . 
 the signals are asymmetric due to radiation of the electron beams.,title="fig:",width=302 ]   distributions for candidates from either @xmath24 or @xmath25 modes . 
 ( b ) the @xmath27 distribution for candidates for candidates from @xmath24 and @xmath25 modes . 
 the solid curves are a fits to the signals plus the backgrounds , that are indicated by the dashed shapes . 
 the signals are asymmetric due to radiation of the electron beams.,title="fig:",width=294 ]    other experiments make use of the both the approximately picosecond lifetimes of charm to identify detached vertices , and the decay @xmath28 , which also serves as a flavor tag in the case of @xmath29 transitions . 
 in charm meson decays , usually a single branching ratio sets the scale for determinations of most other rates , that are measured relative to it . for @xmath2 and @xmath3 
 these modes are @xmath30 and @xmath31 , respectively . 
 cleo - c , on the other hand uses a different technique where the branching ratios of several modes are determined simultaneously and all absolutely . 
 consider an ensemble of modes @xmath22 , that are both singly reconstructed and also doubly reconstructed , where all combinations of modes may be used . 
 i denote the number of observed single tag charmed particles as @xmath32 , anti - charmed particles as @xmath33 , and double tags as @xmath34 . 
 they are related to the number of @xmath13 events ( either charged or neutral ) through their branching ratios @xmath35 as @xmath36 where @xmath37 and @xmath38 are the reconstruction efficiencies in single and double tag events for each mode . 
 ( in practice the differences in each mode between single and double tag events are small , and @xmath39 . ) solving these equations we find @xmath40    cleo - c has recently updated their absolute branching ratio measurements using a 281 pb@xmath41 data sample , an approximately 5 times larger data sample than used by them for their previous publication @xcite . 
 the new preliminary results are shown in table  [ tab : dbr ] @xcite . 
 ( in this table when two errors follow a number , the first error is statistical and the second systematic ; this will be true for all results quoted in this paper unless specifically indicated . ) 
 the absolute branching fractions for charm mesons have been measured with unprecedented accuracy . 
 combining the pdg values with the preliminary cleo - c results for @xmath2 and @xmath3 decays , and using the cleo - c results for @xmath5 , i find @xmath42    cleo - c does not quote a branching ratio for @xmath43 mode because of interferences on the dalitz plot . 
 the @xmath44 or the @xmath45 modes should be used for normalization . 
 since most of the @xmath46 decay modes have been measured as ratios to the @xmath47 mode , i extract an effective branching ratio @xmath48    these rates can be used for many purposes . for example , adding up the number of charm quarks produced in each @xmath49 meson decay at the @xmath50 resonance by summing the @xmath2 , @xmath3 , @xmath5 , charmed baryon and twice the charmonium yields gives a rate of 1.09@xmath140.04 , where the largest error comes from the @xmath2 yield . 
 there is no definitive evidence for @xmath52 mixing . 
 the best limits yet are @xmath53% and @xmath54 both at 95% c. l. the limit on @xmath55 of about 8% is just beginning to probe an interesting range . 
 there are two hints that mixing may be soon found . 
 belle finds consistency with no mixing at 3.9% c. l. in wrong - sign @xmath30 decays and babar finds consistency with no mixing at 4.5% c. l. in wrong sign @xmath56 decays , thus making further searches more interesting . 
 there have not been any observations of cp or t violation . 
 this work was supported by the national science foundation under grant # 0553004 . 
 i thank m.  artuso , d.  asner , r.  faccini , s.  malvezzi , n.  menaa , p.  onysi , r.  sia and s.  stroiney for interesting discussions and providing data and plots used in this review . 
 m. artuso ,  charm decays within the standard model and beyond , " in _ proc . of the xxii int . 
 symp . on lepton & 
 photon interactions at high energies _ , ed . 
 r. brenner , c. p. de los heros , and j. rathsman , world scientific , singapore ( 2006 ) [ hep - ex/0510052 . 
 s. malvezzi , 
 @xmath19-meson dalitz fit from focus , " prepared for 7th conference on intersections between particle and nuclear physics ( cipanp 2000 ) , quebec city , quebec , canada , 22 - 28 may 2000 . published in aip conf 
 . proc . * 549 * , 569 ( 2002 ) . 
 the @xmath57 modes include @xmath58 , @xmath59 , and @xmath60 , that sum to 4.3@xmath140.44 times @xmath61 . 
 the @xmath62 modes include the analgous modes to those for the @xmath57 and , inaddition , feeddown from the @xmath57 modes ; they sum to 9.93@xmath140.95 times @xmath61 . 
 a. petrov ,  charm physics : theoretical review , " invited talk at flavor physics and cp violation ( fpcp 2003 ) , paris , france , 3 - 6 jun 2003 ; published in econf c030603 : mec05 ( 2003 ) http://www.slac.stanford.edu / econf / c030603/.    r. godang _ 
 _  ( cleo ) , phys.rev .  lett . * 84 * , 5038 ( 2000 ) [ hep - ex/0001060 ] 
 . j.  m.  link _ et al . 
 _ ( focus ) , phys . 
 b * 618 * , 23 ( 2005 ) hep - ex/0412034 ] . 
 k.  abe _ et al . _ 
 ( belle ) , phys . 
 lett .   * 94 * , 071801 ( 2005 ) hep - ex/0408125 ] . 
 b.  aubert _ et al . 
 _ ( babar ) , phys .  rev 
 .  lett .   * 91 * , 171801 ( 2003 ) [ hep - ex/0304007 ] . 
 e. m. aitala _ 
 et al . _ 
 ( e791 ) , phys . 
 83 * , 32 ( 1999 ) [ hep - ex/9903012 ] . 
 j. link _ et al . 
 _ ( focus ) , phys . lett . 
 b * 485 * , 62 ( 2000 ) . 
 ( cleo ) , phys . 
 d * 65 * , 092001 ( 2002 ) . 
 et al . _ ( belle ) , phys . 
 lett . * 88 * , 162001 ( 2002 ) . 
 _ ,  meaurement of the @xmath52 lifetime difference using @xmath63 decays , " submitted to lepton - photon conference [ belle - conf-347 ] ( 2003 ) .      c.  cawlfield 
 _ et al . _ ( cleo ) , phys . 
 d * 71 * , 077101 ( 2005 ) [ hep - ex/0502012 ] . 
 b.  aubert _ et al . 
 _ ( babar ) , phys .  rev . 
 d * 70 * , 091102 ( 2004 ) [ hep - ex/0408066 ] . 
 u. bitenc _ 
 et al . _ ( belle ) , phys . rev . 
 * d72 * , 071101 ( 2005 ) [ hep - ex/0507020 ] . 
 d.  m.  asner _ 
 et al . _   ( cleo ) , phys .  rev . 
 d * 72 * , 012001 ( 2005 ) [ hep - ex/0503045 ] . 
 as usual it takes two interfering amplitudes to generate an asymmetry , so no direct sm cp asymmetries can arise in pure cabibbo allowed or doubly - cabibbo suppressed decays . 
 see ref . 
 @xcite p. 258 . 
 asymmetries in singly - cabibbo suppressed decays are very small , on the order of @xmath64 in the sm . 
 x.  c.  tian _ et al . _ 
 ( belle ) , phys . 
 lett . * 95 * , 231801 ( 2005 ) [ hep - ex/0507071 ] . 
 d.  cronin - hennessy _ et al . 
 _ ( cleo ) , phys . 
 d * 72 * , 031102 ( 2005 ) [ hep - ex/0503052 ] . 
 s.  kopp _ et al . 
 _ ( cleo ) , phys .  rev . 
 d * 63 * , 092001 ( 2001 ) [ hep - ex/0011065 ] .
Generated: 
 d.  asner _ et al . 
 _ ( cleo ) , phys . 
 d * 72 * , 012001 ( 2005 ) [ hep - ex/0503046 ] . 
 d.  asner _ et al . 
 _ ( cleo ) , phys . 
 d * 72 * , 012001 ( 2005 ) [ hep - ex/0503047 ] . 
 d.  asner _ et al . 
 _ ( cleo ) , phys . 
 d * 72 * , 012001 ( 2005 ) [ hep - ex/05030
--------------------------------------------------------------------------------

Sample 3:
Input: for fixed integers @xmath0 and @xmath1 , we consider the admissible sequences of @xmath2 lattice paths in a colored @xmath3 square given in @xcite . each admissible sequence of paths can be associated with a partition @xmath10 of @xmath4 . in section 
 [ paths ] , we show that the number of self - conjugate admissible sequences of paths associated with @xmath10 is equal to the number of standard young tableaux of shape @xmath10 , and thus can be calculated using the hook length formula . 
 we extend this result to include the non - self - conjugate admissible sequences of paths and show that the number of all such admissible sequences of paths is equal to the sum of squares of the number of standard young tableaux of partitions of @xmath4 with height less than or equal to @xmath11 . using the rsk correspondence in @xcite , 
 it is shown in ( @xcite , corollary 7.23.12 ) that the sum of squares of the number of standard young tableaux of partitions of @xmath4 with height less than or equal to @xmath11 is equal to the number of @xmath6-avoiding permutations of @xmath7 .    in section [ multiplicities ] 
 , we apply our results to the representation theory of the affine kac - moody algebra @xmath8 . 
 let @xmath12 , @xmath13 and @xmath14 denote the simple roots , simple coroots , and fundamental weights respectively . 
 note that @xmath15 
 . for @xmath16 , set @xmath17 and @xmath18 . as shown in @xcite , @xmath19 
 are maximal dominant weights of the irreducible @xmath8-module @xmath9 . 
 we show that the multiplicity of the weight @xmath19 in @xmath9 is the number of @xmath6-avoiding permutations of @xmath7 , which proves conjecture 4.13 in @xcite . 
 for fixed integers @xmath0 and @xmath1 , consider the @xmath3 square containing @xmath20 unit boxes in the fourth quadrant so that the top left corner of the square is at the origin . 
 we assign color @xmath21 to a box if its upper left corner has coordinates @xmath22 . 
 this gives the following @xmath3 colored square @xmath23 :      a lattice path @xmath25 on @xmath23 is a path joining the lower left corner @xmath26 to the upper right corner @xmath27 moving unit lengths up or right . for two lattice paths @xmath28 on @xmath23 
 we say that @xmath29 if the boxes above @xmath30 are also above @xmath25 . 
 now , we draw @xmath2 lattice paths , @xmath31 on @xmath23 such that @xmath32 . for integers 
 @xmath33 , where @xmath34 , @xmath35 , we define @xmath36 to be the number of @xmath37-colored boxes between @xmath38 and @xmath39 . 
 we define @xmath40 to be the number of @xmath37-colored boxes below @xmath41 and @xmath42 to be the number of @xmath37-colored boxes above @xmath43 . 
 denote by @xmath49 the set of all admissible sequences of @xmath2 paths . 
 notice that there are @xmath4 0-colored boxes in @xmath23 and hence for any admissible sequence of paths , @xmath50 . 
 in addition , it follows from definition [ pathsdef](2 ) that @xmath51 for any admissible sequence of paths . 
 thus , we can and do associate an admissible sequence of paths @xmath44 on @xmath23 with a partition @xmath52 of @xmath4 . in this case , we say that this admissible sequence of paths is of type @xmath10 and often draw @xmath10 as a young diagram . 
 figure [ adseq](a ) is an element of @xmath53 , where @xmath54 and @xmath55 are shown in figures [ adseq](b ) , [ adseq](c ) , and [ adseq](d ) , respectively . 
 notice that this admissible sequence of paths is of type @xmath56 .
Generated: 
 we say that an admissible sequence of paths is self - conjugate if it is of type @xmath56 . 
 we say that an admissible sequence of paths is non - self - conjugate if it is not self - conjugate . 
 we say that an admissible sequence of paths is of type @xmath57 if it is of type @xmath56 and is self - conjugate . 
 we say that an admissible sequence of paths is of type @xmath58 if it is of type @xmath56 and is not self - conjugate . 
 we say that an admissible sequence of paths is of type @x
--------------------------------------------------------------------------------

Sample 4:
Input: a magnitude limited complete census of variable stars in nearby dwarf galaxies allows important contributions to the star formation history of these systems . measurements of some variable stars can supply improved distance determinations for the host galaxies , others will provide important constraints for the population analysis . 
 different classes of variables can further improve the understanding of the star formation history of these system , functioning as tracers of star formation during different epochs . 
 we expect the data set of our long term monitoring program to be especially well suited to study the contents of red long - period variables and to re - investigate the paucity of cepheids with @xmath1 days as reported by sandage & carlson ( 1985 ) . 
 we selected a sample of six local group dwarf irregular galaxies which are visible with the 0.8  m telescope of our institute at mt . 
 the names and additional data from the literature compilation by mateo ( 1998 ) are shown in table 1 . 
 .names , variable star counts , absolute @xmath2-band brightness in mag , and current distance estimation in kpc for the dwarf galaxies observed in our project . 
 the data are taken from the literature compilation by mateo ( 1995 ) . 
 for leo a the data are from the work of dolphin et . 
 al ( 2002 ) and from this work . [ cols="<,<,^,^,^,^,^ " , ]     @xmath3 this work    the observations so far were carried out in @xmath4 and @xmath2-band , sparsely sampling a three year period starting with test observations in 1999 . 
 this part of the data set should be sensitive for long period variable stars with periods up to @xmath5 days . 
 additional observations in @xmath4 , @xmath2 and @xmath6-band were obtained during 3 observing campaigns at the 1.23  m telescope on calar alto densely sampling three two week long periods . 
 these observations should provide a ground for a search for variable stars with shorter periods ranging from @xmath7 days up to @xmath8 days . 
 the acquired data were bias subtracted , flat - fielded and cosmic ray rejected . 
 then , the images from one night were astrometrically aligned to a common reference frame and combined with individual weights proportional to their @xmath9 . for each epoch , consisting of all the stacked images of a single night , a difference image against a common deep reference frame was created using an implementation ( gssl & riffeser , 2002 , 2003 ) of the alard algorithm ( alard & lupton , 1998 ) . 
 finally , these difference images were convolved with a stellar psf .    to extract lightcurves from the reduced data , 
 first all pixels deviating significantly ( @xmath10 ) from the reference image in a minimum number of epochs @xmath11 were flagged , utilizing the complete per - pixel error propagation of our data reduction pipeline . 
 then , using these coordinates as input , values and associated errors are read from the difference images and the lightcurve data are assembled . to search for periodic signals in the extracted difference fluxes , a lomb ( 1976 ) algorithm using the interpretation from scargle ( 1982 ) 
 is applied . 
 the photometric calibration was conducted using the hst data published by schulte - ladbeck et al . 
 for the galaxies leo  a , and ugca  92 , we have a very good monitoring and a large fraction of the data passed already the pipeline . 
 the leo  a data set serves as test case : a total of 26 variable star candidates were detected . among them 
 , we identified 16 secure long period variables ( typical average values @xmath12 , and @xmath13 period [ days ] @xmath14 ) , and we have 8 further candidates for lpvs . 
 in addition we were able to identify two good candidates for @xmath0 cephei stars with best fitting periods of 6.4 and 1.69 days . 
 the later candidate was previously described by dolphin et al . 
 ( 2002 ) as c2-v58 with a period of 1.4 days . the dolphin et al . 
 period solution fails in deriving a reliable lightcurve with our data , yet , applying our period value to their data set yields reasonable results . 
 the phase convolved lightcurves for the two @xmath0 cephei variables are shown in figure  1 . 
 the color magnitude diagram shown in the left panel of figure  2 is based upon the hst data published by tolstoy et al . 
 ( 1996 ) and schulte - ladbeck et al . flagged by bigger symbols 
 are those variables from our sample that lie inside the hst field of view , two @xmath0 cephei variables in the instability strip ( crosses ) and the candidates for long term variability ( triangles ) in the regime of the red giants . 
 tolstoy et al . 
 ( 1996 ) based on ground - based data found a distance modulus for leo  a of 24.2 and a resulting distance of 690 kpc ( see also schulte - ladbeck et al . ) . 
 this result got further support by the search for short periodic variables with the wiyn telescope within 3 consecutive days in dec . 2000 ( dolphin et al . 
 our data complement this dataset for longer periods . 
 the right hand panel of figure  2 shows the period - luminosity ( pl ) relation of the smc shifted to the distance determined by tolstoy et al . 
 the short period variables measured by dolphin coincide with the shown pl relation . 
 the overplotted values for the two cepheids from our survey ( crosses ) support this relation also in the regime of longer periods . 
 we presented preliminary results for our survey for variable stars in a sample of irregular local group dwarf galaxies . for the leo  a dwarf galaxy , the best analysed case so far 
 , we already identified a total of 26 candidates for variability , 16 of these as long period variables and 2 @xmath0 cephei stars . 
 we compared the later with the period - luminosity relation and the short period variables discussed by dolphin et al . 
 we found , that our cepheids fully support their findings and the resulting distance estimate for leo  a. this result is further in good agreement with the trgb distance ( tolstoy et al . 
 , schulte - ladbeck et al . ) . 
 the location of the lpvs in the color - magnitude diagram indicate that most of them are early asymptotic giant branch stars . 
 while a complete census of these intermediate age stars is missing for most of the local group members , a proper statistic of their appearance can guide the reconstruction of the star formation history at the age of several gyr by - passing the age metalicity degeneracy inherent to color magnitude diagram studies . 
 we like to thank drs . 
 i. drozdovsky , c. maraston , r.e . 
 schulte - ladbeck , and e. tolstoy for helpful discussion . 
 we acknowledge the support of the calar alto and wendelstein staff . 
 j. fliri and a. riffeser carried out some of our observations . 
 the project is supported by the deutsche forschungsgemeinschaft grant ho  1812/3 - 1 and ho  1812/3 - 2 . 
 alard , c. & lupton , r. h. , , 503 , 325 dolphin , a. e. et al . 
 2002 , , 123 , 3154 gssl c. a. & riffeser a. 2002 , , 381 , 1095 gssl , c.  a.  & riffeser , a.  2003 , asp conf . 
 295 , 229 lomb n. r. 1976 , , 39 , 447 mateo m. l. 1998 , , 36 , 435 sandage , a. & carlson , g. 1985 , , 90 , 1464 scargle j. d. 1982 , , 263 , 835 schulte - ladbeck r. et al . 
 2002 , , 124 , 896 tolstoy e. et al . 
 1996 , , 116 , 1244
Generated: tolstoy e. et al . 
 2003 , , 127 , 109 tolstoy e. et al . 
 2004 , , 128 , 109 tolstoy e. et al . 
 2005 , , 129 , 109 tolstoy e. et al . 
 2006 , , 130 , 109 tolstoy e. et al . 
 2007 , , 131 , 109 tolstoy e. et al . 
 2
--------------------------------------------------------------------------------

Sample 5:
Input: there are reasons to believe that cosmic rays ( crs ) around the ankle at @xmath0 gev are dominated by extragalactic protons  @xcite . 
 scattering processes in the cosmic microwave background ( cmb ) limit the propagation of ultra high energy ( uhe ) charged particles in our universe . 
 a continuation of a power - like cr spectrum above the greisen - zatsepin - kuzmin ( gzk ) cutoff  @xcite at about @xmath1 gev is only consistent with the proton dominance if the sources lie within the proton attenuation length of about 50 mpc . 
 very few astrophysical accelerators can generate crs with energies above the gzk cutoff  ( see e.g.  @xcite for a review ) and so far none of the candidate sources have been confirmed in our local environment . 
 it has been speculated that decaying superheavy particles , possibly some new form of dark matter or remnants of topological defects , could be a source of uhe crs , but also these proposals are not fully consistent with the cr spectrum at lower energies  @xcite . 
 the observation of gzk excesses has led to speculations about a different origin of uhe crs . 
 berezinsky and zatsepin  @xcite proposed that _ 
 cosmogenic _ neutrinos produced in the decay of the gzk photopions could explain these events assuming a strong neutrino nucleon interaction . 
 we have followed this idea in ref . 
 @xcite and investigated the statistical goodness of scenarios with strongly interacting neutrinos from optically thin sources using cr data from agasa  @xcite and hires  @xcite ( see fig .  [ cr ] ) and limits from horizontal events at agasa  @xcite and contained events at rice  @xcite . 
 -branes , and string excitations ( see ref . 
 @xcite ) . ] 
 the flux of uhe extragalactic protons from distant sources is redshifted and also subject to @xmath2 pair production and photopion - production in the cmb which can be taken into account by means of propagation functions . 
 the resonantly produced photopions provide a _ guaranteed _ source of cosmogenic uhe neutrinos observed at earth . in astrophysical accelerators inelastic scattering of the beam protons off the ambient photon gas in the source will also produce photopions which provide an additional source of uhe neutrinos . the corresponding spectrum will in general depend on the details of the source such as the densities of the target photons and the ambient gas  @xcite . 
 we have used the flux of crs from _ optically thin _ sources using the luminosities given in ref . 
 @xcite in the goodness - of - fit test .    for a reasonable and consistent contribution of extragalactic neutrinos in vertical crs 
 one has to assume a strong and rapid enhancement of the neutrino nucleon interaction . 
 the realization of such a behavior has been proposed in scenarios beyond the ( perturbative ) sm ( see ref . 
 @xcite ) . for convenience 
 , we have approximated the strong neutrino nucleon cross section in our analysis by a @xmath3-behavior shown in fig . 
 [ fig ] , parameterized by the energy scale and width of the transition , and the amplification compared to the standard model predictions . 
 our analysis showed that uhe crs measured at agasa and hires can be interpreted to the 90% cl as a composition of extragalactic protons and strongly interacting neutrinos from optically thin sources in agreement with experimental results from horizontal events at agasa and contained events at rice ( see fig . 
 [ fig ] ) . 
 the pierre auger observatory combines the experimental techniques of agasa and hires as a hybrid detector . with a better energy resolution , much higher statistics and also stronger bounds on horizontal showers 
 it will certainly help to clarify our picture of uhe crs in the future . 
 the author would like to thank the organizers of the erice school on nuclear physics 2005 _ `` neutrinos in cosmology , in astro , particle and nuclear physic '' _ for the inspiring workshop and vihkos ( _ `` virtuelles institut fr hochenergiestrahlungen aus dem kosmos '' _ ) for support . 
 m.  ahlers , a.  ringwald , and h.  tu , _ astropart . 
 ( to appear ) , preprint astro - ph/0506698 . 
 v.  berezinsky , a.  z.  gazizov and s.  i.  grigorieva , preprint hep - ph/0204357 ; v.  berezinsky , a.  z.  gazizov and s.  i.  grigorieva , . 
 m.  ahlers _ 
 et  al . _ , . 
 k.  greisen , ; g.  t.  zatsepin and v.  a.  kuzmin , . 
 d.  f.  torres and l.  a.  anchordoqui , . 
 d.  v.  semikoz and g.  sigl , . 
 v.  s.  beresinsky and g.  t.  zatsepin , . 
 m.  takeda _ 
 et  al . _ [ agasa ] , . 
 d.  j.  bird _ 
 et  al . _ 
 [ hires ] , ; r.  u.  abbasi _ et  al . _ [ hires ] , ; r.  u.  abbasi _ et  al . _ [ hires ] , . s.  yoshida _ 
 _ [ agasa ] , .
Generated: 
 m.  ahlers _ 
 et  al . _ [ rice ] , . 
 m.  ahlers _ 
 et  al . _ [ rice ] , . 
 m.  ahlers _ 
 et  al . _ [ rice ] , . 
 m.  ahlers _ 
 et  al . _ [ rice ] , . 
 m.  ahlers _ 
 et  al . _ [ rice ] , . 
 m.  ahlers _ 
 et  al . _ [ rice ] , . 
 m.  ahlers _ 
 et  al . _ [ rice ] , . 
--------------------------------------------------------------------------------

Sample 6:
Input: in solid - core photonic crystal fibers ( pcf ) the air - silica microstructured cladding ( see fig .  [ fig1 ] ) gives rise to a variety of novel phenomena  @xcite including large - mode area ( lma ) endlessly - single mode operation @xcite . 
 though pcfs typically have optical properties very different from that of standard fibers they of course share some of the overall properties such as the susceptibility of the attenuation to macro - bending . 
 macrobending - induced attenuation in pcfs has been addressed both experimentally as well as theoretically / numerically in a number of papers @xcite . however , predicting bending - loss is no simple task and typically involves a full numerical solution of maxwell s equations as well as use of a phenomenological free parameter , _ 
 e.g. _ an effective core radius . in this paper 
 we revisit the problem and show how macro - bending loss measurements on high - quality pcfs can be predicted with high accuracy using easy - to - evaluate empirical relations . 
 predictions of macro - bending induced attenuation in photonic crystal fibers have been made using various approaches including antenna - theory for bent standard fibers @xcite , coupling - length criteria @xcite , and phenomenological models within the tilted - index representation @xcite . here 
 , we also apply the antenna - theory of sakai and kimura  @xcite , but contrary to refs . 
 @xcite we make a full transformation of standard - fiber parameters such as @xmath1 , @xmath2 , and @xmath0 @xcite to fiber parameters appropriate to high - index contrast pcfs with a triangular arrangement of air holes . in the large - mode area 
 limit we get ( see appendix )    @xmath3    for the power - decay , @xmath4 , along the fiber . for a conversion to a db - scale @xmath5 should be multiplied by @xmath6 . in eq . 
 ( [ alpha_lma ] ) , @xmath7 is the bending radius , @xmath8 is the effective area @xcite , @xmath9 is the index of silica , and @xmath10 is the recently introduced effective v - parameter of a pcf  @xcite . 
 the strength of our formulation is that it contains no free parameters ( such as an arbitrary core radius ) and furthermore empirical expressions , depending only on @xmath11 and @xmath12 , have been given recently for both @xmath8 and @xmath13 @xcite .    from the function 
 @xmath14 we may derive the parametric dependence of the critical bending radius @xmath15 . 
 the function increases dramatically when the argument is less than unity and thus we may define a critical bending radius from @xmath16 where @xmath17 . typically the pcf is operated close to cut - off where @xmath18  @xcite so that the argument may be written as    @xmath19    this dependence was first reported and experimentally confirmed by birks 
 _ et al . _ 
 @xcite and recently a pre - factor of order unity was also found experimentally in ref . 
 we have fabricated three lma fibers by the stack - and - pull method and characterized them using the conventional cut - back technique . 
 all three fibers have a triangular air - hole array and a solid core formed by a single missing air - hole in the center of the structure , see fig . 
 [ fig1 ] .    for the lma-20 macro - bending loss has been measured for bending radii of r=8 cm and r=16 cm and 
 the results are shown in fig . 
 the predictions of eq . 
 ( [ alpha_lma ] ) are also included . 
 it is emphasized that the predictions are based on the empirical relations for @xmath8 and @xmath13 provided in refs . @xcite and @xcite respectively and therefore do not require any numerical calculations . 
 similar results are shown in figs . 
 [ fig3 ] and [ fig4 ] for the lma-25 and lma-35 fibers , respectively . 
 the pcf , in theory , exhibits both a short and long - wavelength bend - edge . 
 however , the results presented here only indicate a short - wavelength bend - edge . 
 the reason for this is that the long - wavelength bend - edge occurs for @xmath20 @xcite . for typical lma - pcfs 
 it is therefor located in the non - transparent wavelength regime of silica . 
 in conclusion we have demonstrated that macro - bending loss measurements on high - quality pcfs can be predicted with good accuracy using easy - to - evaluate empirical relations with only @xmath21 and @xmath22 as input parameters . 
 since macro - bending attenuation for many purposes and applications is the limiting factor we believe that the present results will be useful in practical designs of optical systems employing photonic crystal fibers . 
 the starting point is the bending - loss formula for a gaussian mode in a standard - fiber @xcite    @xmath23    where @xmath8 is the effective area , @xmath24 is the core radius , @xmath7 is the bending radius , and the standard - fiber parameters are given by @xcite @xmath25 substituting these parameters into eq . 
 ( [ alpha1 ] ) we get    @xmath26    in the relevant limit where @xmath27 . here , 
 @xmath28 and @xmath29 in eqs .  ( [ alpha_lma ] ) and ( [ v_pcf ] ) have been introduced . for large - mode area fibers we make a further simplification for the isolated propagation constant ; using that @xmath30 we arrive at eq . 
 ( [ alpha_lma ] ) . 
 m.  d. nielsen acknowledges financial support by the danish academy of technical sciences .
Generated: 
































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































































--------------------------------------------------------------------------------

Sample 7:
Input: a fair number of astronomers and astronomy students have a physical challenge . 
 it is our responsibility to learn the basics of accessibility to be able to help our library patrons to gain access to things that they need for their studies and work . 
 astronomy is often seen as a very visual science . 
 after all , its origins lie in looking at the skies . 
 hence , it is a common belief that you need to use your sight to be able to study astronomy . 
 this is strictly not true . in reality 
 , we have been using assistive technologies  telescopes , sensors , computers  for a long time now to gain access to data that the human eye does not see unaided . 
 visual information is coming to us as large streams of bytes . 
 the modern astronomer is hardly bound by physical limitations . 
 one can produce solid research sitting comfortably in front of one s personal computer . 
 there are many examples of physically challenged individuals who have made successful careers in science . 
 those who have seen the movie _ contact _ based on carl sagan s novel are familiar with the blind astronomer who is listening to radio signals instead of watching them on the screen . 
 his character is based on a real scientist , dr . d. kent cullers . 
 there are other success stories  in fact , too many to enumerate here . 
 but , you ask , is nt the sheer amount of information a major hindrance to those who can not browse it easily ? yes , it is  to some degree . 
 electronic textual materials provide both a possibility and a challenge for those with low vision . in theory , it is possible for almost anyone to access online information , but in practice , this requires know - how and proper tools . 
 plenty of assistive technologies exist to overcome hindrances . 
 the daisy standard for digital talking books has been an important tool for making electronic texts easy to browse . 
 not all hindrances are in the visual domain . 
 imagine an elderly astronomer who has the full use of his or her intelligence , but whose hands are shaking , and who might have some difficulty with pointing a mouse when navigating a webpage and filling out search forms .    it is a challenging task for librarians and information specialists to make our services and search forms accessible to people with a diversity of abilities so that they can do the research necessary for building careers as active contributors in their chosen fields of research . 
 but what does accessibility look like ? 
 there is a pervasive myth that it looks boring . 
 this is strictly not true . 
 accessible design should be functional enough , not just pretty . with proper html code and other techniques , we can make the text compliant with technological aids . 
 if the html coding is poor , a document may be impossible to open with such aids or it could be impossible to navigate the text . 
 the author of this paper was involved with an university - wide accessibility project that was undertaken by the university of helsinki in 20052006 , with a follow up in 20082009 . 
 it was recognized that accessibility must cover not only our physical surroundings , but also the online environment as well .    in spring 2009 
 , we noticed that the new national online system for applying for university education was not accessible to blind students . 
 the system was provided by the finnish ministry of education , and we challenged them to fix it . to our big surprise , they did , working in collaboration with us and the finnish federation of the visually impaired . 
 figure 1 shows a page from the application system . 
 it looks exactly the same both before and after accessibility changes were made . 
 differences can be seen on the coding level , but otherwise one can not tell the old version from the new one by visual inspection alone . the change has resulted in a major functional improvement . the old version could not even be opened with assistive technology , and blind students could not use it . now they can . 
 accessibility needs some muscle to drive it . 
 it is not just about good people doing good deeds  it is also about ensuring that everyone has access to things that matter to them . 
 we need guidelines and standards , preferably with legislation to back them up .    in the united states , section 508 of the rehabilitation act 
 regulates purchases made with federal funding . 
 it is about `` access to and use of information and data that is comparable to that provided to others . '' 
 a market for accessible products helps big publishers to take accessibility into account . when a publisher has a large enough number of customers who need to buy accessible products , they will be motivated to sell accessible products . 
 we also need strong standards . the world wide consortium has updated its web content accessibility guidelines ( wcag )  version 2 dates back to 2008 . 
 this new version of wcag is meant to be a practical tool , evidenced by its three levels of accessibility :    * a : minimum * aa : medium * aaa : as accessible as possible    you will find a good wcag2 checklist online . 
 the ideal thing to do would be to make your website as accessible as possible , but in practice you need to read the guidelines and identify the accessibility level best suited to serving your users . 
 let s look at a concrete example by applying an a - level guideline to an existing search form . 
 the guideline states : `` form inputs have associated text labels or , if labels can not be used , a descriptive title attribute . '' 
 let s look at a part of an ads search form with its original coding . 
 this piece of code is from the section which requires an object for selection .    0.2 in    _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ` 
 < input name = obj_req value = yes type = checkbox > require object for selection ` _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _    0.2 in    let s add some more coding ( in boldface ) . rather than just a checkbox , we now have a _ text label_.    0.2 in    _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ ` < input id = obj_req name = obj_req value = yes type = checkbox > < label for = obj_req > require object for selection</label > ` _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _    0.2 in    figure 2 shows what has changed . the text label in question has been highlighted . 
 it is no longer necessary to hit the small checkbox 
 it is enough if you just click the associated text . 
 this makes the box much easier to check . 
 you can do clever things with html . 
 there are however many other formats to consider : pdf , flash , and office products , to name just a few . 
 no matter what the material at hand , it needs structure above all else . otherwise , a blind person who tries to read a text has to read everything from beginning to end and is not able to navigate to a chapter or a footnote . 
 even pdf which used to be an accessibility nightmare can now boast of a structure to make it more accessible 
 it s called tagged pdf .    as a general guideline , 
 no matter what kind of document you are writing , you will need to stick to structure . 
 do you use subtitles that are bold and in a different font ? 
 please , use proper titles instead and use styles to control the fonts and such . 
 let s take a peek at an html page that has structure . 
 there are tools to make the structure visible . 
 the box in figure 3 has been done with a wave toolbar . 
 this example is taken from _ 
 planetary and space science_. a good amount of structure has been revealed . 
 the html structure of _ earth , moon and planets _ , shows next to nothing . 
 its only structure is a references header , `` h2 references . '' 
 there is no subtitle structure at all that you can jump to . 
 most publishers make their electronic materials available in pdf format . 
 usually , those files are without any structure . 
 figure 4 shows the acrobat reader results of an accessibility quick check  there is no structure . 
 what is the current situation with different astronomy publishers and journals ? 
 table 1 shows accessibility elements for a selection of publishers based on inspection of a few papers published in 2009 by university of helsinki astronomers . 
 we asked some questions about the basic properties of each paper . 
 is there html fulltext ? 
 does it have structure ? and does the pdf have structure ? if not , are there at least pdf bookmarks ? 
 you can see that these results leave a lot to hope for . 
 the only consistently good results are from _ planetary and space science _ , which is published by elsevier . 
 unfortunately , however , not all elsevier products are equally accessible . 
 llcccc title & publisher & html & html & pdf & + & & fulltext & structure & structure & bookmarks + astronomy & astrophysics & edp sciences & yes & ok & no & yes + astrophysical journal & iop & yes & none & no & yes + monthly notices r.a.s . & wiley & yes & none & no & no + astron . 
 nachrichten & wiley & no &  & no & no + planetary space sci . & 
 elsevier & yes & ok & yes & yes + earth , moon & planets & springer & yes & none & no & yes +    elsevier was the winner of this brief check . 
 it has been making some efforts to increase accessibility of its products , which sets a good example for other big publishers . 
 @xcite have inspected the overall accessibility compliance and practices of major database vendors , elsevier included .    even if major publishers are making some progress , it is not enough . 
 there are also smaller publishers , and beyond that there are institutes and libraries producing their own online materials or making their own search forms . 
 many of them are unaware of current accessibility standards . 
 standards can seem difficult to apply . 
 but really , they are easy to follow if we make the guidelines clear enough so that everyone can understand and use them . 
 remember that new technologies are taken into use all the time . 
 we will be constantly facing new challenges to make them accessible , but they will also bring new possibilities with them . 
 there is one last thing that you need to be aware of  do nt forget about copyright . 
 it is not a given fact that a library can freely distribute electronic material to a patron who could then read it on a personal computer or some other device . 
 the copyright laws in different countries vary surprisingly on this point . moreover , 
 even when the right to access is written into a law , thus making special exceptions to copyright for disabled persons , a license agreement between a library and a publisher might take this right away for particular electronic materials or products . a publisher or 
 a consortium will not allow you to do things that are not specifically stated in the signed agreement . 
 please always remember to check the accessibility options in agreements you sign .    to give an example , 
 the current finnish national electronic library ( finelib ) consortium agreement with elsevier specifies that `` coursepacks in nonelectronic , non - print perceptible form ( e.g. braille ) may be offered for [ the ] visually impaired . '' 
 this is not , however , how visually impaired users would like to use the materials . 
 this is a standard clause that should be modified to meet real needs . 
 unfortunately , when the consortium was formed , this clause did not receive the proper attention it should have . 
 practically everyone who lives long enough has to face physical challenges at some point . 
 an astronomer who is able - bodied today could have accessibility issues tomorrow . 
 we can not expect that she or he is willing to give up practicing science . in her essay _ the blind astronomer _ 
 @xcite , the new zealand astronomer tracy farr eloquently describes the changes brought by the gradual loss of her vision . with a different approach to looking at the research data 
 , she can continue to access the universe :    _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ i am freeing myself from the fixedness of the seen . with my mind 
 open to the universe , i hear the heavens ebb and flow as music . 
 it is the incomprehensibly wonderful revelation of music first heard after only ever having seen black spots and lines on a white page . 
 as my ears open and my eyes close , i hear the planets dance . 
 _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
Generated: _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
--------------------------------------------------------------------------------

Sample 8:
Input: in adaptive control and recursive parameter estimation one often needs to adjust recursively an estimate @xmath0 of a vector @xmath1 , which comprises @xmath2 constant but unknown parameters , using measurements of a quantity @xmath3 here @xmath4 is a vector of known data , often called the regressor , and @xmath5 is a measurement error signal . 
 the goal of tuning is to keep both the estimation error @xmath6 and the parameter error @xmath7 as small as possible . 
 there are several popular methods for dealing with the problem above , for instance least - squares . 
 maybe the most straightforward involve minimizing the prediction error via gradient - type algorithms of the form : @xmath8 where @xmath9 is a constant , symmetric , positive - definite gain matrix . 
 let us define @xmath10 and analyze differential equations and , which under the assumption that @xmath11 is identically zero read : @xmath12 the nonnegative function @xmath13 has time derivative @xmath14 hence @xmath15    inspection of the equation above reveals that @xmath16 is limited in time , thus @xmath17 , and also that the error @xmath18 ( norms are taken on the interval @xmath19 where all signals are defined ) . 
 these are the main properties an algorithm needs in order to be considered a suitable candidate for the role of a tuner in an adaptive control system . 
 often @xmath20 or something similar is also a desirable property . to obtain the latter , normalized algorithms can be used ; however , the relative merits of normalized versus unnormalized tuners are still somewhat controversial . 
 another alternative is to use a time - varying @xmath9 , as is done in least - squares tuning .    in  [ sec : acceleration ] we present a tuner that sets the second derivative of @xmath0 , and in  [ sec : covariance ] the effects of a white noise @xmath5 on the performance of the two algorithms are compared . 
 then we show some simulations and make concluding remarks . 
 classical tuners are such that the _ velocity _ of adaptation ( the first derivative of the parameters ) is set proportional to the regressor and to the prediction error @xmath21 . 
 we propose to set the _ acceleration _ of the parameters : @xmath22 notice that the the formula above is implementable ( using @xmath23 integrators ) if measurement error is absent , because the unknown @xmath24 appears only in scalar product with @xmath25 . 
 choose another function of lyapunovian inspiration : @xmath26 taking derivatives along the trajectories of gives @xmath27 integrating @xmath28 we obtain @xmath29 which leads immediately to the desired properties : @xmath30    the slow variation property @xmath31 follows without the need for normalization , and now we obtain @xmath32 instead of @xmath33 as before 
 . we might regard @xmath34 as a modified error , which can be used in the stability analysis of a detectable or `` tunable '' adaptive system via an output - injection argument ; see @xcite . 
 a generalization of is @xmath35 with @xmath36 and @xmath37 constant , symmetric , positive - definite @xmath38 matrices such that @xmath39 and @xmath40 . 
 the properties of tuner , which can be obtained using the positive - definite function @xmath41 in the same manner as before , are @xmath42 
 we now consider the effects on the expected value and covariance of @xmath43 of the presence of a measurement error . 
 the assumptions are that @xmath11 is a white noise with zero average and covariance @xmath44 and that @xmath45 are given , deterministic data . for comparison purposes , first consider what happens when the conventional tuner is applied to in the presence of measurement error @xmath5 : @xmath46 the solution to the equation above can be written in terms of @xmath47 s state transition matrix @xmath48 as follows @xmath49 hence @xmath50 because @xmath51 by assumption . here 
 the notation @xmath52 , denoting the expectation with respect to the random variable @xmath5 , is used to emphasize that the stochastic properties of @xmath25 are not under consideration . 
 the conclusion is that @xmath43 will converge to zero in average as fast as @xmath53 does . 
 the well - known persistency of excitation conditions on @xmath54 are sufficient for the latter to happen .    to study the second moment of the parameter error , write @xmath55 
 the covariance of @xmath43 can be written as the sum of four terms . 
 the first is deterministic . 
 the second term @xmath56 because @xmath11 has zero mean , and the third term is likewise zero . 
 the fourth term @xmath57 where fubini s theorem and the fact @xmath58 were used . 
 performing the integration and adding the first and fourth terms results in @xmath59 this equation can be given the following interpretation : for small @xmath60 , when @xmath53 is close to the identity , the covariance of @xmath43 remains close to @xmath61 , the outer product of the error in the initial guess of the parameters with itself . 
 as @xmath62 , which will happen if @xmath54 is persistently exciting , @xmath63 tends to @xmath64 . 
 this points to a compromise between higher convergence speeds and lower steady - state parameter error , which require respectively larger and smaller values of the gain @xmath9 . 
 algorithms that try for the best of both worlds  parameter convergence in the mean - square sense  often utilize time - varying , decreasing gains ; an example is the least - squares algorithm . 
 we shall now attempt a similar analysis for the acceleration tuner applied to , which results in the differential equation @xmath65 let @xmath66 where @xmath67 , @xmath68 , each @xmath69 is a function of @xmath70 unless otherwise noted , and the dot signifies derivative with respect to the first argument . if @xmath71 , @xmath72    following the same reasoning used for the velocity tuner , one concludes that @xmath73 and that @xmath74 however the properties of the acceleration and velocity tuners are not yet directly comparable because the right - hand side of does not lend itself to immediate integration . to obtain comparable results 
 , we employ the ungainly but easily verifiable formula ,    @xmath75    ' '' ''    valid for arbitrary scalars @xmath76 and @xmath77 , and make the    [ [ simplifying - assumption ] ] simplifying assumption : + + + + + + + + + + + + + + + + + + + + + + + +    for @xmath78 , and 3 , @xmath79 , where @xmath80 are scalars and @xmath81 is the @xmath82 identity matrix .    premultiplying by @xmath83 $ ] , postmultiplying by @xmath83^\top$ ] , integrating from 0 to @xmath60 , and using the simplifying assumption gives formula . 
 @xmath84    ' '' ''    taking @xmath85 in , @xmath86 results positive - semidefinite , therefore @xmath87    the combination of and shows that @xmath88 can be increased without affecting @xmath24 s steady - state covariance . on the other hand , to decrease the covariance we need to increase @xmath89 , which roughly speaking means increasing damping in . since @xmath88 and @xmath89 can be increased without affecting the stability properties shown in 
 [ sec : acceleration ] , a better transient @xmath90 steady - state performance compromise might be achievable with the acceleration tuner than with the velocity tuner , at least in the case when @xmath91 , @xmath92 , and @xmath37 are `` scalars . '' 
 notice that @xmath93 by construction . 
 [ [ approximate - analysis ] ] approximate analysis : + + + + + + + + + + + + + + + + + + + + + +    the derivation of inequality does not involve any approximations , and therefore provides an upper bound on @xmath94 , valid independently of @xmath54 . 
 a less conservative estimate of the integral in can be obtained by replacing @xmath95 by its average value @xmath96 in the definition of @xmath86 in . 
 this approximation seems reasonable because @xmath86 appears inside an integral , but calls for more extensive simulation studies .    to obtain a useful inequality , 
 we require @xmath97 ; namely , using the schur complement @xmath98 or , using the simplifying assumption and substituting @xmath95 by its approximation @xmath96 @xmath99 suppose further that @xmath100 . 
 looking for the least conservative estimate , we pick @xmath101 , the least value of @xmath76 that keeps @xmath97 . 
 thus @xmath102 with @xmath103 \bar{m}_1 \left[\begin{smallmatrix}{\phi}^\top_{11}(t,0 ) \\ { \phi}^\top_{12}(t,0 )   \end{smallmatrix}\right]}{4m_1 ^ 2 m_2m_3r(1+\mu_2 ) -r}.$ ]    taking @xmath104 we repeat the previous , exact result . for large positive values of @xmath77 
 the first term of the right - hand side of tends to @xmath105 , which indicates that the steady - state covariance of the parameter error decreases when the signal @xmath25 increases in magnitude , and that it can be made smaller via appropriate choices of the gains @xmath88 and @xmath106 . 
 the situation for the accelerating tuner is hence much more favorable than for the conventional one . 
 the simulations in this section compare the behavior of the accelerating tuner with those of the gradient tuner and of a normalized gradient one . 
 all simulations were done in open - loop , with the regressor a two - dimensional signal , and without measurement noise . 
 figure  [ fig : step ] shows the values of @xmath107 and @xmath108 respectively when @xmath25 is a two - dimensional step signal . in figure 
 [ fig : sin ] the regressor is a sinusoid , in figure  [ fig : sia ] an exponentially increasing sinusoid , and in figure  [ fig : prb ] a pseudorandom signal generated using matlab . 
 no effort was made to optimize the choice of gain matrices ( @xmath91 , @xmath92 , and @xmath37 were all chosen equal to the identity ) , and the effect of measurement noise was not considered . 
 the performance of the accelerating tuner is comparable , and sometimes superior , to that of the other tuners . 
 = 2.5 in = 2.5 in    = 2.5 in = 2.5 in    = 2.5 in = 2.5 in    = 2.5 in = 2.5 in 
 other ideas related to the present one are replacing the integrator in with a positive - real transfer function @xcite , and using high - order tuning ( @xcite ) . 
 high - order tuning generates as outputs @xmath0 as well as its derivatives up to a given order ( in this sense we might consider the present algorithm a second - order tuner ) , but unlike the accelerating tuner requires derivatives of @xmath25 up to that same order . 
 we expect that accelerating tuners will find application in adaptive control of nonlinear systems and maybe in dealing with the topological incompatibility known as the `` loss of stabilizability problem '' in the adaptive control literature . 
 the stochastic analysis in  [ sec : covariance ] indicates that the performance and convergence properties of the accelerating tuner , together with its moderate computational complexity , may indeed make it a desirable tool for adaptive filtering applications . 
 it seems that a better transient @xmath90 steady - state performance compromise is achievable with the accelerating tuner than with the velocity tuner . to verify this conjecture , a study of convergence properties of the accelerating tuner and their relation with the persistence of excitation conditions 
 is in order , as well as more extensive simulations in the presence of measurement noise .
Generated: 
 the present work was supported by the National Science Foundation under grant no. 9404545 . 
 the authors would like to thank the referees for their helpful comments . 
 the authors would also like to thank the editor and the associate editor for their help in the preparation of this paper . 
 the authors would like to thank the referees for their helpful comments . 
 the authors would
--------------------------------------------------------------------------------

Sample 9:
Input: although the sunspot number varies periodically with time with an average period of 11 year , the individual cycle period ( length ) and also the strength ( amplitude ) vary in a random way . 
 it is observed that the stronger cycles have shorter periods and vice versa . 
 this leads to an important feature of solar cycle known as waldmeier effect . 
 it says that there is an anti - correlation between the rise time and the peak sunspot number . 
 we call this as we1 . 
 now instead of rise time if we consider the rise rate then we get very tight positive correlation between the rise rate and the peak sunspot number . 
 we call this as we2 
 .    another important aspect of solar activity are the grand minima . 
 these are the periods of strongly reduced activity . 
 a best example of these is the  during during 16451715 . 
 it was not an artifact of few observations , but a real phenomenon ( hoyt & schatten 1996 ) . from the study of the cosmogenic isotope @xmath0c data in tree rings , usoskin et al . 
 ( 2007 ) reported that there are @xmath1 grand minimum during last @xmath2 years . 
 we want to model these irregularities of solar cycle using flux transport dynamo model ( choudhuri et al . 1995 ; dikpati & charbonneau 1999 ; chatterjee et al . 
 2004 ) . in this model 
 , the turbulent diffusivity is an important ingredient which is not properly constrained . 
 therefore several groups use different value of diffusivity and this leads to two kinds of flux transport dynamo model  high diffusivity model and low diffusivity model . in the earlier model , 
 the value of diffusivity usually used is @xmath3 @xmath4 s@xmath5 ( see also jiang et al . 2007 and yeates et al . 
 2008 for details ) , whereas in the latter model , it is @xmath6 @xmath4 s@xmath5 . 
 we mention that the mixing length theory gives the value of diffusivity as @xmath7 @xmath4 s@xmath5 . 
 another important flux transport agent in this model is the meridional circulation . only since 1990 
 s we have some observational data of meridional circulation near the surface and therefore we do not know whether the  varied largely with solar cycle in past or not . 
 however if the flux transport dynamo is the correct dynamo for the solar cycle , then one can consider the solar cycle period variation as the variation for the  because the cycle period is strongly determined by the strength of the meridional circulation in this model . 
 now the periods of the solar cycle indeed had much variation in past , then we can easily say that the  had significant variation with the solar cycle . 
 therefore the main sources of randomness in the flux transport dynamo model are the stochastic fluctuations in  process of generating poloidal field and the stochastic fluctuations in the meridional circulation . in this paper 
 we explore the effects of fluctuations of the latter . 
 we model last @xmath8 cycles by fitting the periods with variable meridional circulation in a high diffusivity model based on chatterjee et al . 
 ( 2004 ) model . 
 the solid line in fig . 
 [ fit23](a ) shows the variation of the amplitude of  @xmath9 used to model the periods of the cycles . 
 note that we did not try to match the periods of each cycles accurately which is bit difficult . 
 we change @xmath9 between two cycles and not during a cycle . 
 in addition , we do not change @xmath9 if the period difference between two successive cycles is less than @xmath10 of the average period . 
 ( in m  s@xmath5 ) with time ( in yr ) . 
 the solid line is the variation of @xmath9 used to match the theoretical periods with the observed periods . 
 ( b ) variation of theoretical sunspot number ( dashed line ) and observed sunspot number ( solid line ) with time . 
 ( c ) scatter diagram showing peak theoretical sunspot number and peak observed sunspot number . 
 the linear correlation coefficients and the corresponding significance levels are given on the plot.,scaledwidth=100.0% ]    in fig . 
 [ fit23](b ) , we show the theoretical sunspot series ( eruptions ) by dashed line along with the observed sunspot series by solid line . 
 the theoretical sunspot series has been multiplied by a factor to match the observed value . 
 it is very interesting to see that most of the amplitudes of the theoretical sunspot cycle have been matched with the observed sunspot cycle . 
 therefore , we have found a significant correlation between these two ( see fig .  [ 
 fit23](c ) ) . 
 this study suggests that a major part of the fluctuations of the amplitude of the solar cycle may come from the fluctuations of the meridional circulation . 
 this is a very important result of this analysis . 
 now we explain the physics of this result based on yeates et al . 
 toroidal field in the flux transport model , is generated by the stretching of the poloidal field in the tachocline . 
 the production of this toroidal field is more if the poloidal field remains in the tachocline for longer time and vice versa . 
 however , the poloidal field diffuses during its transport through the convection zone . as a result , 
 if the diffusivity is very high , then much of the poloidal field diffuses away and very less amount of it reaches the tachocline to induct toroidal field . therefore , when we decrease @xmath9 in high diffusivity model to match the period of a longer cycle , the poloidal field gets more time to diffuse during its transport through the convection zone . 
 this ultimately leads to a lesser generation of toroidal field and hence the cycle becomes weaker . 
 on the other hand , when we increase the value of @xmath9 to match the period of a shorter cycle , the poloidal field does not get much time to diffuse in the convection zone . 
 hence it produces stronger toroidal field and the cycle becomes stronger . 
 consequently , we get weaker amplitudes for longer periods and vice versa . 
 however , this is not the case in low diffusivity model because in this model the diffusive decay of the fields are not much important . as a result 
 , the slower meridional circulation means that the poloidal field remains in the tachocline for longer time and therefore it produces more toroidal field , giving rise to a strong cycle . 
 therefore , we do not get a correct correlation between the amplitudes of theoretical sunspot number and that of observed sunspot number when repeat the same analysis in low diffusivity model based on dikpati & charbonneau ( 1999 ) model . 
 we study the  using flux transport dynamo model . 
 we have seen that the stochastic fluctuations in the  process and the stochastic fluctuations in the  are the two main sources of irregularities in this model . 
 therefore , to study  we first introduce suitable stochastic fluctuations in the poloidal field source term of  process . 
 we see that this study can not reproduce we1 ( fig . 
 [ pol](a ) ) . 
 however it reproduces we2 ( fig . 
 [ pol](b ) ) .                  finally we introduce stochastic fluctuations in both the poloidal field source term and the meridional circulation . 
 we see that both we1 and we2 are remarkably reproduced in this case ( see fig . 
 [ both ] ) . 
 we repeat the same study in low diffusivity model based on dikpati & charbonneau ( 1999 ) model . 
 however in this case we are failed to reproduce we1 , only we2 is reproduced . 
 the details of this work can be found in karak & choudhuri ( 2011 ) . 
 we have realized that the  is important in modeling many aspects of solar cycle . 
 therefore we check whether a large decrease of the  leads to a maunder - like grand minimum . to answer this question 
 , we decrease @xmath9 to a very low value in both the hemispheres . 
 we have done this in the decaying phase of the last sunspot cycle before maunder minimum . 
 we keep @xmath9 at low value for around 1  yr and then we again increase it to the usual value but at different rates in two hemispheres . in northern hemisphere , @xmath9 is increased at slightly lower rate than southern hemisphere . 
 ( in m  s@xmath5 ) in northern and southern hemispheres with time . 
 ( b ) the butterfly diagram . 
 ( c ) the dashed and dotted lines show the sunspot numbers in southern and northern hemispheres , whereas the solid line is the total sunspot number . 
 ( d ) variation of energy density of toroidal field at latitude 15@xmath11 at the bottom of the convection zone.,scaledwidth=100.0% ]    in fig . 
 [ mm ] , we show the theoretical results covering the maunder minimum episode . fig .  [ mm](a ) , shows the maximum amplitude of meridional circulation @xmath9 varied over this period in two hemispheres . in fig . 
 [ mm](b ) , we show the butterfly diagram of sunspot numbers , whereas in fig . 
 [ mm](c ) , we show the variation of total sunspot number along with the individual sunspot numbers in two hemispheres ( see the caption ) . in order to facilitate comparison with observational data 
 , we have taken the beginning of the year to be 1635 . 
 note that our theoretical results reproduce the sudden initiation and the gradual recovery , the north - south asymmetry of sunspot number observed in the last phase of maunder minimum and the cyclic oscillation of solar cycle found in cosmogenic isotope data . 
 we also mention that if we reduce the poloidal field to a very low value at the beginning of the maunder minimum then also we can reproduce maunder - like grand minimum ( choudhuri & karak 2009 ) . 
 however in both the cases , either we need to reduce the  or the poloidal field at the beginning of the maunder minimum . 
 however if we reduce the poloidal field little bit , then one can reproduce maunder - like grand minimum at a moderate value of meridional circulation . 
 the details of this study can be found in karak ( 2010 ) . 
 we have shown that with a suitable stochastic fluctuations in the meridional circulation , we are able to reproduce many important irregular features of solar cycle including waldmeier effect and maunder like grand minimum . 
 however we are failed to reproduce these results in low diffusivity model . 
 therefore this study along with some earlier studies ( chatterjee , nandy & choudhuri 2004 ; chatterjee & choudhuri 2006 ; goel & choudhuri 2009 ; jiang , chatterjee & choudhuri 2007 ; karak 2010 ; karak & choudhuri 2011 ; karak & choudhuri 2012 ) supports the high diffusivity model for solar cycle . 
 chatterjee , p. , nandy , d. , & choudhuri , a. r. 2004 , a&a , 427 , 1019 choudhuri , a.  r. , chatterjee , p. , & jiang , j. , 2007 , phys . 
 , 98 , 1103 choudhuri , a. r. , & karak , b. b. 2009 , raa 9 , 953 choudhuri , a. r. , schssler , m. , & dikpati , m. 1995 , a&a , 303 , l29 dikpati , m. , & charbonneau , p. 1999 , apj , 518 , 508 jiang , j. , chatterjee , p. , & choudhuri , a. r. 2007 , mnras , 381 , 1527 hoyt , d. v. , & schatten , k. h. , 1996 , sol . 
 phys . , 165 , 181 karak , b. b. 2010 , apj , 724 , 1021 karak , b. b. , & choudhuri , a. r. 2011 , 
 mnras , 410 , 1503 karak , b. b. , & choudhuri , a. r. 2012 , sol . 
 , 278:137 usoskin , i. g. , solanki , s. k. , & kovaltsov , g. a. 2007 , a&a , 471 , 301 yeates , a. r. , nandy , d. , & mackay , d. h. 2008 , apj , 673 , 544
Generated: 











































































































































































































--------------------------------------------------------------------------------

Sample 10:
Input: in @xcite a database containing a solution of the 3d incompressible navier - stokes ( ns ) equations is presented . 
 the equations were solved numerically with a standard pseudo - spectral simulation in a periodic domain , using a real space grid of @xmath0 grid points . 
 a large - scale body force drives a turbulent flow with a taylor microscale based reynolds number @xmath1 . out of this solution , 
 @xmath2 snapshots were stored , spread out evenly over a large eddy turnover time . 
 more on the simulation and on accessing the data can be found at http://turbulence.pha.jhu.edu . in practical terms 
 , we have easy access to the turbulent velocity field and pressure at every point in space and time . 
 one usual way of visualising a turbulent velocity field is to plot vorticity isosurfaces  see for instance the plots from @xcite . 
 the resulting pictures are usually very `` crowded '' , in the sense that there are many intertwined thin vortex tubes , generating an extremely complex structure . 
 in fact , the picture of the entire dataset from @xcite looks extremely noisy and it is arguably not very informative about the turbulent dynamics .    in this work , 
 we follow a different approach . 
 first of all , we use the alternate quantity @xmath3 first introduced in @xcite . 
 secondly , the tool being used has the option of displaying data only inside clearly defined domains of 3d space . 
 we can exploit this facility to investigate the multiscale character of the turbulent cascade . because vorticity is dominated by the smallest available scales in the velocity 
 , we can visualize vorticity at scale @xmath4 by the curl of the velocity box - filtered at scale @xmath4 . 
 we follow a simple procedure :    * we filter the velocity field , using a box filter of size @xmath5 , and we generate semitransparent surfaces delimitating the domains @xmath6 where @xmath7 ; * we filter the velocity field , using a box filter of size @xmath8 , and we generate surfaces delimitating the domains @xmath9 where @xmath10 , but only if these domains are contained in one of the domains from @xmath6 ;    and this procedure can be used iteratively with several scales ( we use at most 3 scales , since the images become too complex for more levels ) . 
 additionally , we wish sometimes to keep track of the relative orientation of the vorticity vectors at the different scales . for this purpose 
 we employ a special coloring scheme for the @xmath11 isosurfaces : for each point of the surface , we compute the cosine of the angle @xmath12 between the @xmath13 filtered vorticity and the @xmath5 filtered vorticity : @xmath14 the surface is green for @xmath15 , yellow for @xmath16 and red for @xmath17 , following a continuous gradient between these three for intermediate values . 
 the opening montage of vortex tubes is very similar to the traditional visualisation : a writhing mess of vortices . upon coarse - graining 
 , additional structure is revealed . 
 the large - scale vorticity , which appears as transparent gray , is also arranged in tubes .    as a next step , 
 we remove all the fine - scale vorticity outside the large - scale tubes . the color scheme for the small - scale vorticity 
 is that described earlier , with green representing alignment with the large - scale vorticity and red representing anti - alignment . 
 clearly , most of the small - scale vorticity is aligned with the vorticity of the large - scale tube that contains it . 
 we then remove the fine - grained vorticity and pan out to see that the coarse - grained vortex tubes are also intricately tangled and intertwined . introducing a yet larger scale , we repeat the previous operations 
 . the relative orientation properties of the vorticity at these two scales is similar to that observed earlier . 
 next we visualize the vortex structures at all three scales simultaneously , one inside the other . 
 it is clear that the small vortex tubes are transported by the larger tubes that contain them . 
 however , this is not just a passive advection . 
 the small - scale vortices are as well being distorted by the large - scale motions .    to focus on this more clearly 
 , we now render just the two smallest scales . 
 one can observe the small - scale vortex tubes being both stretched and twisted by the large - scale motions . 
 the stretching of small vortex tubes by large ones was suggested by orszag and borue @xcite as being the basic mechanism of the turbulent energy cascade . 
 as the small - scale tubes are stretched out , they are `` spun up '' and gain kinetic energy . here , this phenomenon is clearly revealed . 
 the twisting of small - scale vortices by large - scale screw motions has likewise been associated to helicity cascade @xcite . 
 the video thus allows us to view the turbulent cascade in progress . 
 next we consider the corresponding view with three levels of vorticity simultaneously . 
 since the ratio of scales is here 1:15:49 we are observing less than two decades of the turbulent cascade . 
 one must imagine the complexity of a very extended inertial range with many scales of motion . 
 not all of the turbulent dynamics is tube within tube . in our last scene 
 we visualize in the right half domain all the small - scale vortices , and in the left domain only the small - scale vortices inside the larger scale ones . in the right half , 
 the viewer can observe stretching of the small - scale vortex structures taking place externally to the large - scale tubes . 
 the spin - up of these vortices must contribute likewise to the turbulent energy cascade . 
 6ifxundefined [ 1 ] ifx#1 ifnum [ 1 ] # 1firstoftwo 
 secondoftwo ifx [ 1 ] # 1firstoftwo secondoftwo `` `` # 1''''@noop [ 0]secondoftwosanitize@url [ 0 ]  + 12$12  & 12#1212_12%12@startlink[1]@endlink[0]@bib@innerbibempty link:\doibase 10.1080/14685240802376389 [ * * ( ) ,  10.1080/14685240802376389 ] @noop * * ( ) ,   in  http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1592886[__ ] ( )  p.   @noop _ _ ,   ( ) link:\doibase 10.1017/s0022112097008306 [ * * ,   ( ) ] http://journals.cambridge.org / production / action / cjogetfulltext?fulltextid=4% 00523 [ * * ,   ( ) ]
Generated: @noop * * ,   ( ) link:\doibase 10.1016/j.jnnfm.2008.06.001 [ * * ,   ( ) ] http://www.sciencedirect.com/science/article/pii/S0022246308000609 [ * * ,   ( ) ] @noop * * ,   ( ) link:\doibase 10.1016/j.jnnfm.2008.06.001 [ * * ,   ( ) ] http
--------------------------------------------------------------------------------
Total time: 40.78
