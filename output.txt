
==========
== CUDA ==
==========

CUDA Version 12.4.1

Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.

This container image and its contents are governed by the NVIDIA Deep Learning Container License.
By pulling and using the container, you accept the terms and conditions of this license:
https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license

A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience.

/usr/local/lib/python3.10/dist-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
No module named 'vllm._version'
  from vllm.version import __version__ as VLLM_VERSION
2025-09-10 14:46:33.882 | INFO     | cgen.engine:__init__:335 - init process group using port 49485
/usr/local/lib/python3.10/dist-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
No module named 'vllm._version'
  from vllm.version import __version__ as VLLM_VERSION
/usr/local/lib/python3.10/dist-packages/vllm/connections.py:8: RuntimeWarning: Failed to read commit hash:
No module named 'vllm._version'
  from vllm.version import __version__ as VLLM_VERSION
2025-09-10 14:46:39.759 | INFO     | cgen.engine:__init__:97 - loading model...
2025-09-10 14:46:39.759 | INFO     | cgen.engine:__init__:98 - partitioning model...
2025-09-10 14:46:39.952 | INFO     | cgen.engine:__init__:97 - loading model...
2025-09-10 14:46:39.952 | INFO     | cgen.engine:__init__:98 - partitioning model...
2025-09-10 14:46:39.965 | INFO     | cgen.dist_utils:_create_process_groups:28 - create proc groups tp=0/1 pp=1/2
2025-09-10 14:46:39.965 | INFO     | cgen.dist_utils:_create_process_groups:28 - create proc groups tp=0/1 pp=0/2
2025-09-10 14:46:40.101 | INFO     | cgen.dist_utils:_create_process_groups:28 - create proc groups tp=1/2 pp=0/1
2025-09-10 14:46:40.101 | INFO     | cgen.dist_utils:_create_process_groups:28 - create proc groups tp=0/2 pp=0/1
INFO 09-10 14:46:40 utils.py:1008] Found nccl from library libnccl.so.2
INFO 09-10 14:46:40 utils.py:1008] Found nccl from library libnccl.so.2
INFO 09-10 14:46:40 pynccl.py:63] vLLM is using nccl==2.20.5
INFO 09-10 14:46:40 pynccl.py:63] vLLM is using nccl==2.20.5
Process SpawnProcess-2:
Process SpawnProcess-1:
Traceback (most recent call last):
Traceback (most recent call last):
  File "/usr/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/usr/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/workspace/cgen/cgen/engine.py", line 301, in _work_proc
    worker = Worker(*args, **kwargs)
  File "/workspace/cgen/cgen/engine.py", line 113, in __init__
    self.model = self._load_model(dist_config_prefill)
  File "/usr/lib/python3.10/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/workspace/cgen/cgen/engine.py", line 141, in _load_model
    model = create_model(
  File "/usr/lib/python3.10/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/workspace/cgen/cgen/models/__init__.py", line 15, in create_model
    return model_cls(model_config, *args, **kwargs)
  File "/workspace/cgen/cgen/engine.py", line 301, in _work_proc
    worker = Worker(*args, **kwargs)
  File "/workspace/cgen/cgen/models/llama.py", line 283, in __init__
    self.model = DistLlamaModel(
  File "/workspace/cgen/cgen/models/llama.py", line 259, in __init__
    DistLlamaDecoder(
  File "/workspace/cgen/cgen/engine.py", line 113, in __init__
    self.model = self._load_model(dist_config_prefill)
  File "/workspace/cgen/cgen/models/llama.py", line 187, in __init__
    self.mlp = DistLlamaMLP(
  File "/workspace/cgen/cgen/engine.py", line 141, in _load_model
    model = create_model(
  File "/workspace/cgen/cgen/models/llama.py", line 146, in __init__
    self.down_proj = LinearLayer(isz, hsz, False, device, torch.half)
  File "/workspace/cgen/cgen/models/__init__.py", line 15, in create_model
    return model_cls(model_config, *args, **kwargs)
  File "/workspace/cgen/cgen/layers/linear.py", line 21, in __init__
    self.weight = torch.empty(
  File "/workspace/cgen/cgen/models/llama.py", line 283, in __init__
    self.model = DistLlamaModel(
  File "/workspace/cgen/cgen/models/llama.py", line 259, in __init__
    DistLlamaDecoder(
  File "/workspace/cgen/cgen/models/llama.py", line 187, in __init__
    self.mlp = DistLlamaMLP(
  File "/workspace/cgen/cgen/models/llama.py", line 146, in __init__
    self.down_proj = LinearLayer(isz, hsz, False, device, torch.half)
  File "/workspace/cgen/cgen/layers/linear.py", line 21, in __init__
    self.weight = torch.empty(
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 112.00 MiB. GPU 1 has a total capacity of 22.05 GiB of which 55.00 MiB is free. Including non-PyTorch memory, this process has 7.45 GiB memory in use. Of the allocated memory 7.09 GiB is allocated by PyTorch, and 1.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 112.00 MiB. GPU 0 has a total capacity of 22.05 GiB of which 55.00 MiB is free. Including non-PyTorch memory, this process has 7.45 GiB memory in use. Of the allocated memory 7.09 GiB is allocated by PyTorch, and 1.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
